{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GRU network with pretrained vectors for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, gc, numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Permute, GRU, Conv1D, LSTM, Embedding, Dropout, Activation, CuDNNLSTM, CuDNNGRU, concatenate, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, BatchNormalization, SpatialDropout1D, Dot\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from functools import reduce\n",
    "from keras.layers import Layer, PReLU, SpatialDropout1D, TimeDistributed, Subtract\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, TweetTokenizer, MWETokenizer, ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "np.random.seed(786)\n",
    "\n",
    "from Tokenizer import Tokenizer\n",
    "from ZeroMaskedLayer import ZeroMaskedLayer\n",
    "from AttentionLayer import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/'\n",
    "utility_path = '../utility/'\n",
    "comp = 'jigsaw-toxic-comment-classification-challenge/'\n",
    "EMBEDDING_FILE=f'{utility_path}crawl-300d-2M.vec'\n",
    "TRAIN_DATA_FILE=f'{path}train.csv'\n",
    "TEST_DATA_FILE=f'{path}test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(series):\n",
    "    return series.apply(lambda s: unicodedata.normalize('NFKC', str(s)))\n",
    "\n",
    "\n",
    "def multiple_replace(text, adict):\n",
    "    rx = re.compile('|'.join(map(re.escape, adict)))\n",
    "\n",
    "    def one_xlat(match):\n",
    "        return adict[match.group(0)]\n",
    "\n",
    "    return rx.sub(one_xlat, text)\n",
    "\n",
    "STOP_WORDS = set(stopwords.words( 'english' ))\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(series):\n",
    "    series = unicodeToAscii(series)\n",
    "    series = series.str.lower()\n",
    "    series = series.str.replace(r\"(\\n){1,}\", \" \")\n",
    "    series = series.str.replace(r\"\\'\", \"\")\n",
    "    series = series.str.replace(r\"\\-\", \"\")\n",
    "    series = series.str.replace(r\"[^0-9a-z]+\", \" \")\n",
    "    series = series.str.replace(\"([a-z0-9]{2,}\\.){2,}[a-z]{2,}\", \" \") \n",
    "    series = series.str.replace(\" \\d \", \"\")\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8) (153164, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "\n",
    "#Get validation folds\n",
    "train['target_str'] = reduce(lambda x,y: x+y, [train[col].astype(str) for col in list_classes])\n",
    "train['target_str'] = train['target_str'].replace('110101', '000000').replace('110110','000000')\n",
    "cvlist1 = list(StratifiedKFold(n_splits=10, random_state=786).split(train, train['target_str'].astype('category')))\n",
    "cvlist2 = list(StratifiedShuffleSplit(n_splits=5, test_size=0.05, random_state=786).split(train, train['target_str'].astype('category')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in train, test:\n",
    "    df[\"comment_text\"] = normalizeString(df[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ha ha im on episodeso fuck u now let me spoil it basicly jack dad kill theguys drive to his brothers house interrogate him brother tells him that he ist he one behind all of the last season and then his dad kills jacks bro the end'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.comment_text.sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 200) (153164, 200)\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = 200000\n",
    "MAX_LEN = 200\n",
    "\n",
    "tok = Tokenizer(max_features=MAX_FEATURES, max_len=MAX_LEN, tokenizer=wordpunct_tokenize)\n",
    "X = tok.fit_transform(pd.concat([train[\"comment_text\"].astype(str), test[\"comment_text\"].astype(str)]))\n",
    "X_train = X[:len(train), :]\n",
    "X_test = X[len(train):, :]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384733"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del train, testlen()\n",
    "len(tok.doc_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 300\n",
    "oov_list= []\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def initialize_embeddings(filename, tokenizer):\n",
    "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(filename))\n",
    "\n",
    "    word_index = tokenizer.vocab_idx\n",
    "    nb_words = min(MAX_FEATURES, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        if i > MAX_FEATURES: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            oov_list.append(word)\n",
    "    return  embedding_matrix, oov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 300)\n",
      "0.0029242610409603276 0.2315748370561002\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, oov_list = initialize_embeddings(EMBEDDING_FILE, tok)\n",
    "print(embedding_matrix.shape)\n",
    "print(np.mean(embedding_matrix), np.std(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92089"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nihh', 1),\n",
       " ('pletnikov', 1),\n",
       " ('mhdisc1', 1),\n",
       " ('disruptedinschizophrenia1', 1),\n",
       " ('transgenicmouseoffersawindowongeneenvironmentinterplayprenatalinfectionaltersbehavioringeneticallyvulnerable',\n",
       "  1),\n",
       " ('strategicplanningreports', 1),\n",
       " ('breakinggroundbreakingthroughthestrategicplanformooddisordersresearch', 1),\n",
       " ('monastries', 1),\n",
       " ('casecomments', 1),\n",
       " ('onlyitems', 1),\n",
       " ('pkt7wfyollo', 1),\n",
       " ('letitgo', 1),\n",
       " ('dynampic', 1),\n",
       " ('noveseminarys', 1),\n",
       " ('nietrality', 1),\n",
       " ('resumelike', 1),\n",
       " ('khud', 1),\n",
       " ('jaata', 1),\n",
       " ('dusor', 1),\n",
       " ('hamesha', 1),\n",
       " ('taiyaar', 1),\n",
       " ('rehte', 1),\n",
       " ('kaheen', 1),\n",
       " ('khush', 1),\n",
       " ('aake', 1),\n",
       " ('dunga', 1),\n",
       " ('chuda', 1),\n",
       " ('bhosdke', 1),\n",
       " ('kiya', 1),\n",
       " ('xebat', 1),\n",
       " ('archivesarchivearchivearchivearchiveso', 1),\n",
       " ('highfashion', 1),\n",
       " ('japhethic', 1),\n",
       " ('philistia', 1),\n",
       " ('fylfot', 1),\n",
       " ('fractionary', 1),\n",
       " ('topnotable', 1),\n",
       " ('geographics', 1),\n",
       " ('ab1axxvarhy', 1),\n",
       " ('porcom', 1),\n",
       " ('porkom', 1),\n",
       " ('protoceltic', 1),\n",
       " ('refuring', 1),\n",
       " ('notifyonline', 1),\n",
       " ('asespnencylopedia', 1),\n",
       " ('britannicathe', 1),\n",
       " ('m7ahblq3', 1),\n",
       " ('multiband', 1),\n",
       " ('gootersmooch', 1),\n",
       " ('page17', 1),\n",
       " ('entwinged', 1),\n",
       " ('353538', 1),\n",
       " ('rught', 1),\n",
       " ('wasvote', 1),\n",
       " ('ended5ths', 1),\n",
       " ('exconfederates', 1),\n",
       " ('page111', 1),\n",
       " ('roundhouses', 1),\n",
       " ('darkhorse', 1),\n",
       " ('violiting', 1),\n",
       " ('groupusclules', 1),\n",
       " ('gdzietobylo', 1),\n",
       " ('eurobandio', 1),\n",
       " ('euroband', 1),\n",
       " ('60ft', 1),\n",
       " ('matay', 1),\n",
       " ('kalamata', 1),\n",
       " ('redirectthis', 1),\n",
       " ('vvs', 1),\n",
       " ('docess', 1),\n",
       " ('portay', 1),\n",
       " ('hindutwa', 1),\n",
       " ('jacksoncountysports', 1),\n",
       " ('mon7', 1),\n",
       " ('gearsolid', 1),\n",
       " ('variantinteractive', 1),\n",
       " ('25html', 1),\n",
       " ('face217', 1),\n",
       " ('kramgasse', 1),\n",
       " ('gerechtigkeitsgasse', 1),\n",
       " ('his307thousand', 1),\n",
       " ('cloggin', 1),\n",
       " ('suzis', 1),\n",
       " ('exarmy', 1),\n",
       " ('catford', 1),\n",
       " ('smudger', 1),\n",
       " ('wintersmith', 1),\n",
       " ('brockley', 1),\n",
       " ('132ft', 1),\n",
       " ('1982tony', 1),\n",
       " ('z900', 1),\n",
       " ('jamesat', 1),\n",
       " ('lizzette', 1),\n",
       " ('gainedworld', 1),\n",
       " ('ardingly', 1),\n",
       " ('forwheel', 1),\n",
       " ('alsoother', 1),\n",
       " ('expeidency', 1),\n",
       " ('mbekis', 1),\n",
       " ('meddlingnovember', 1)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.doc_freq.most_common(200000)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class GRUClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, gru_dim=150, dense_dim=256, batch_size=128, epochs=2, bidirectional=False, \n",
    "                 pool_type='all', initial_weights=None, optimizer='adam' ,verbose=1, out_dim=6, callbacks=None,\n",
    "                spatial_drop=0.0, dropout=0.0, mask_zero=True, \n",
    "                gru_kernel_regularization = 0.0001,\n",
    "                gru_recurrent_regularization = 0.0001,\n",
    "                gru_bias_regularization = 0.0001,\n",
    "                embeddings_regularization = 0.0,\n",
    "                ):\n",
    "        \n",
    "        self.gru_dim = gru_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs= epochs\n",
    "        self.bidirectional = bidirectional\n",
    "        self.pool_type = pool_type\n",
    "        self.initial_weights = initial_weights\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.optimizer = optimizer\n",
    "        self.out_dim = out_dim\n",
    "        self.spatial_drop = spatial_drop\n",
    "        self.dropout = dropout\n",
    "        self.mask_zero = mask_zero\n",
    "        self.gru_kernel_regularization = gru_kernel_regularization\n",
    "        self.gru_recurrent_regularization = gru_recurrent_regularization\n",
    "        self.gru_bias_regularization = gru_bias_regularization\n",
    "        self.embeddings_regularization = embeddings_regularization\n",
    "        \n",
    "    def _build_model(self):\n",
    "        inp = Input(shape=(MAX_LEN,))\n",
    "        emb = Embedding(MAX_FEATURES, \n",
    "                        EMBED_SIZE,\n",
    "                        weights=[self.initial_weights],\n",
    "                        mask_zero=self.mask_zero,\n",
    "                        #embeddings_regularizer=regularizers.l2(self.embeddings_regularization),\n",
    "                        trainable=False)(inp)\n",
    "\n",
    "        if self.mask_zero:\n",
    "            emb = ZeroMaskedLayer()(emb)\n",
    "            \n",
    "        emb = SpatialDropout1D(self.spatial_drop)(emb)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            enc = Bidirectional(CuDNNGRU(int(self.gru_dim), return_sequences=True, return_state=True,\n",
    "                                         ))(emb)\n",
    "            x = enc[0]\n",
    "            state = enc[1]\n",
    "            \n",
    "            enc = Bidirectional(CuDNNGRU(int(self.gru_dim), return_sequences=True, return_state=True,\n",
    "                                         ))(emb)\n",
    "            x = enc[0]\n",
    "            state = enc[1]\n",
    "        else:\n",
    "            x, state = CuDNNGRU(int(self.gru_dim), return_sequences=True, return_state=True,\n",
    "                            kernel_regularizer=regularizers.l2(self.gru_kernel_regularization),\n",
    "                            recurrent_regularizer=regularizers.l2(self.gru_recurrent_regularization),\n",
    "                            bias_regularizer=regularizers.l2(self.gru_bias_regularization)\n",
    "                               )(emb)\n",
    "            #x = TimeDistributed(Dense(100, activation='relu'))(x)\n",
    "            #x = CuDNNGRU(150, return_sequences=True)(x)\n",
    "            #x = SpatialDropout1D(0.5)(x)\n",
    "        \n",
    "        if self.pool_type == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'max':\n",
    "            x = GlobalMaxPool1D()(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'attn':\n",
    "            x = AttentionLayer(MAX_LEN)(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'all':\n",
    "            #x1 = GlobalAveragePooling1D()(emb)\n",
    "            x2 = GlobalMaxPool1D()(x)\n",
    "            x3 = AttentionLayer(MAX_LEN)(x)\n",
    "            x4 = Subtract()([x2, x3])\n",
    "            x = concatenate([x2, x3, state])\n",
    "    \n",
    "        x = Dropout(self.dropout)(x)\n",
    "        x = Dense(self.dense_dim)(x)\n",
    "        x = PReLU()(x)\n",
    "        \n",
    "        #x = Dense(self.dense_dim)(x)\n",
    "        #x = PReLU()(x)\n",
    "\n",
    "        out = Dense(self.out_dim, activation=\"sigmoid\")(x)\n",
    "        if self.optimizer == 'adam':\n",
    "            opt = Adam(lr=0.001, decay=0.0, clipnorm=5.0)\n",
    "        elif self.optimizer == 'rmsprop':\n",
    "            opt = RMSprop(clipnorm=1.0)\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "        if self.callbacks:\n",
    "            self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                       verbose=self.verbose,\n",
    "                       callbacks=self.callbacks,\n",
    "                       shuffle=True)\n",
    "        else:\n",
    "            self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                       verbose=self.verbose,\n",
    "                       shuffle=True)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        if self.model:\n",
    "            y_hat = self.model.predict(X, batch_size=1024)\n",
    "        else:\n",
    "            raise ValueError(\"Model not fit yet\")\n",
    "        return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(epoch):\n",
    "    if epoch == 0:\n",
    "        return 0.001\n",
    "    if epoch == 1:\n",
    "        return 0.0008\n",
    "    if epoch == 2:\n",
    "        return 0.001\n",
    "    if epoch == 3:\n",
    "        return 0.00001\n",
    "\n",
    "\n",
    "def shuffle_crossvalidator(model, cvlist, X, y, lr_decay):\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    scores = []\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        print(\"ROC AUC for this fold is \", score)\n",
    "        y_trues.append(y_val)\n",
    "        y_preds.append(y_pred)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        #break\n",
    "    y_trues = np.concatenate(y_trues)\n",
    "    y_preds = np.concatenate(y_preds)\n",
    "    score = roc_auc_score(y_trues, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, scores\n",
    "\n",
    "def outoffold_crossvalidator(model_params, cvlist, X, y, lr_decay):\n",
    "    y_preds = np.zeros(y.shape)\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "        \n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        print(\"ROC AUC for this fold is \", roc_auc_score(y_val, y_pred))\n",
    "        y_preds[val_idx] = y_pred\n",
    "        K.clear_session()\n",
    "        break\n",
    "    score = roc_auc_score(y, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9782\n",
      " ROC-AUC - epoch: 1 - score: 0.984911 \n",
      "\n",
      "151592/151592 [==============================] - 61s 399us/step - loss: 0.0607 - acc: 0.9782\n",
      "Epoch 2/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9827\n",
      " ROC-AUC - epoch: 2 - score: 0.988786 \n",
      "\n",
      "151592/151592 [==============================] - 62s 406us/step - loss: 0.0453 - acc: 0.9827\n",
      "Epoch 3/5\n",
      " 71424/151592 [=============>................] - ETA: 31s - loss: 0.0426 - acc: 0.9833"
     ]
    }
   ],
   "source": [
    "def lr_decay(epoch):\n",
    "    if epoch == 0:\n",
    "        return 0.001\n",
    "    if epoch == 1:\n",
    "        return 0.001\n",
    "    if epoch == 2:\n",
    "        return 0.001\n",
    "    if epoch == 3:\n",
    "        return 0.001\n",
    "    return 0.001\n",
    "model = GRUClassifier(gru_dim=300, dense_dim=512, initial_weights=embedding_matrix, bidirectional=True,\n",
    "                    batch_size=256, epochs=5, optimizer='adam', pool_type='all', spatial_drop=0.4, \n",
    "                      dropout=0.15)\n",
    "\n",
    "y_preds, y_trues, _ = shuffle_crossvalidator(model, cvlist2, X_train, y, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "143583/143593 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9802\n",
      " ROC-AUC - epoch: 1 - score: 0.982053 \n",
      "\n",
      "143593/143593 [==============================] - 255s 2ms/step - loss: 0.0572 - acc: 0.9802\n",
      "Epoch 2/2\n",
      " 76475/143593 [==============>...............] - ETA: 1:57 - loss: 0.0696 - acc: 0.9788"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-bdcf57b4db9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m            )\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-bdcf57b4db9a>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(parameter_space)\u001b[0m\n\u001b[1;32m     55\u001b[0m                           )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle_crossvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvlist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_trues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score for parameters {} is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-c316ee895cb2>\u001b[0m in \u001b[0;36mshuffle_crossvalidator\u001b[0;34m(model, cvlist, X, y, lr_decay)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRocAuc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRDecay\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-f2cc5a65a129>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    100\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                        \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                        shuffle=True)\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "def uniform_int(name, lower, upper):\n",
    "    # `quniform` returns:\n",
    "    # round(uniform(low, high) / q) * q\n",
    "    return hp.quniform(name, lower, upper, q=1)\n",
    "\n",
    "def loguniform_int(name, lower, upper):\n",
    "    # Do not forget to make a logarithm for the\n",
    "    # lower and upper bounds.\n",
    "    return hp.qloguniform(name, np.log(lower), np.log(upper), q=1)\n",
    "\n",
    "parameter_space = {\n",
    "    'gru_dim': uniform_int('gru_dim', 50, 600),\n",
    "    'dense_dim': uniform_int('dense_dim', 100, 1000),\n",
    "    'lr1': hp.uniform('lr1', 0.0001, 0.005),\n",
    "    'lr2': hp.uniform('lr2', 0.0001, 0.005),\n",
    "    'spatial_drop': hp.uniform('spatial_drop', 0, 0.5),\n",
    "    'dropout': hp.uniform('dropout', 0, 0.5),\n",
    "    'batch_size': loguniform_int('batch_size', 16, 512),\n",
    "    'mask_zero': hp.choice('mask_zero', [True, False]),\n",
    "    'optimizer': hp.choice('optimizer', ['adam', 'rmsprop']),\n",
    "    'pool_type': hp.choice('pool_type', ['avg', 'max', 'attn', 'all']),\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False]),\n",
    "    'gru_kernel_reg': hp.loguniform('gru_kernel_reg', np.log(1e-10), np.log(1e-4)),\n",
    "    'gru_recc_reg': hp.loguniform('gru_recc_reg', np.log(1e-10), np.log(1e-4)),\n",
    "    'gru_bias_reg': hp.loguniform('gru_bias_reg', np.log(1e-10), np.log(1e-4)),\n",
    "    #'embeddings_reg': hp.loguniform('embeddings_reg', 1e-8, 1e-4)\n",
    "}\n",
    "\n",
    "\n",
    "def objective(parameter_space):\n",
    "    \n",
    "    def lr_decay(epoch):\n",
    "        if epoch == 0:\n",
    "            return parameter_space['lr1']\n",
    "        if epoch == 1:\n",
    "            return parameter_space['lr2']\n",
    "    \n",
    "    model = GRUClassifier(initial_weights=embedding_matrix, bidirectional=False,\n",
    "                          gru_dim = int(parameter_space['gru_dim']),\n",
    "                          dense_dim = int(parameter_space['dense_dim']),\n",
    "                          mask_zero = parameter_space['mask_zero'],\n",
    "                          pool_type = parameter_space['pool_type'],\n",
    "                          batch_size= int(parameter_space['batch_size']), \n",
    "                          epochs=5, \n",
    "                          optimizer=parameter_space['optimizer'],\n",
    "                          dropout=parameter_space['dropout'],\n",
    "                          spatial_drop=parameter_space['spatial_drop'],\n",
    "                          gru_kernel_regularization = parameter_space[\"gru_kernel_reg\"],\n",
    "                          gru_recurrent_regularization = parameter_space[\"gru_recc_reg\"],\n",
    "                          gru_bias_regularization = parameter_space[\"gru_bias_reg\"],\n",
    "                          #embeddings_regularization = parameter_space[\"embeddings_reg\"],\n",
    "                          )\n",
    "\n",
    "    y_preds, y_trues, scores = shuffle_crossvalidator(model, cvlist1, X_train, y, lr_decay)    \n",
    "    score = roc_auc_score(y_trues, y_preds)\n",
    "    print(\"Score for parameters {} is {}\".format(parameter_space, score))\n",
    "    #return score\n",
    "    return {\n",
    "        'loss': -1* score,\n",
    "        'status': STATUS_OK,\n",
    "        'other_Stuff': {'scores': scores, 'variance': np.std(scores)},\n",
    "        }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(objective,\n",
    "    space=parameter_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials\n",
    "           )\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = [{'batch_size': [47.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [973.0],\n",
    "  'dropout': [0.19862535182199834],\n",
    "  'gru_bias_reg': [1.011936859273273e-08],\n",
    "  'gru_dim': [358.0],\n",
    "  'gru_kernel_reg': [2.0678669679829352e-10],\n",
    "  'gru_recc_reg': [8.946942716621634e-07],\n",
    "  'lr1': [0.0015982451490776767],\n",
    "  'lr2': [0.0002459290205687559],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.2696100622336198]},\n",
    " {'batch_size': [83.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [351.0],\n",
    "  'dropout': [0.07833431778315075],\n",
    "  'gru_bias_reg': [1.989216237371643e-09],\n",
    "  'gru_dim': [478.0],\n",
    "  'gru_kernel_reg': [2.1606860352426398e-10],\n",
    "  'gru_recc_reg': [1.6736919208281796e-07],\n",
    "  'lr1': [0.00263784102869703],\n",
    "  'lr2': [0.0005711207564167526],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.21401382410917008]},\n",
    " {'batch_size': [49.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [997.0],\n",
    "  'dropout': [0.19115533803668047],\n",
    "  'gru_bias_reg': [5.222640591389245e-10],\n",
    "  'gru_dim': [399.0],\n",
    "  'gru_kernel_reg': [8.078459790975857e-10],\n",
    "  'gru_recc_reg': [6.100081276448957e-08],\n",
    "  'lr1': [0.0019427338445684181],\n",
    "  'lr2': [0.00010186610979091696],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.22614208466560007]},\n",
    " {'batch_size': [41.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [973.0],\n",
    "  'dropout': [0.20050865242539928],\n",
    "  'gru_bias_reg': [1.1451922219328368e-08],\n",
    "  'gru_dim': [392.0],\n",
    "  'gru_kernel_reg': [1.0516629869555607e-09],\n",
    "  'gru_recc_reg': [1.2593577396164419e-06],\n",
    "  'lr1': [0.0016205788115723873],\n",
    "  'lr2': [0.00011538601448660545],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.3803897135211322]},\n",
    " {'batch_size': [37.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [237.0],\n",
    "  'dropout': [0.12273937792021693],\n",
    "  'gru_bias_reg': [2.7055793227129377e-09],\n",
    "  'gru_dim': [407.0],\n",
    "  'gru_kernel_reg': [1.9122269544090935e-09],\n",
    "  'gru_recc_reg': [1.5269966614646778e-06],\n",
    "  'lr1': [0.0019545667587842147],\n",
    "  'lr2': [0.00034205962093229346],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.239366738134983]},\n",
    " {'batch_size': [16.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [783.0],\n",
    "  'dropout': [0.19251258375962352],\n",
    "  'gru_bias_reg': [1.6889374260262626e-08],\n",
    "  'gru_dim': [401.0],\n",
    "  'gru_kernel_reg': [2.1685591958268602e-10],\n",
    "  'gru_recc_reg': [8.179324804312695e-07],\n",
    "  'lr1': [0.0016526011543532724],\n",
    "  'lr2': [0.00020256532886638333],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.3994866402536531]},\n",
    " {'batch_size': [90.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [995.0],\n",
    "  'dropout': [0.22199634608987717],\n",
    "  'gru_bias_reg': [1.162462425352503e-10],\n",
    "  'gru_dim': [234.0],\n",
    "  'gru_kernel_reg': [2.6194833614316782e-09],\n",
    "  'gru_recc_reg': [3.719163247084088e-10],\n",
    "  'lr1': [0.002927034550684743],\n",
    "  'lr2': [0.0003517541152030026],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.01670368024684063]},\n",
    " {'batch_size': [71.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [999.0],\n",
    "  'dropout': [0.31884760544934115],\n",
    "  'gru_bias_reg': [3.489577142351314e-10],\n",
    "  'gru_dim': [310.0],\n",
    "  'gru_kernel_reg': [3.464891994757166e-10],\n",
    "  'gru_recc_reg': [1.5572206853920122e-09],\n",
    "  'lr1': [0.0019593704753874588],\n",
    "  'lr2': [0.000472320376364918],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.0905500602659617]},\n",
    " {'batch_size': [21.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [971.0],\n",
    "  'dropout': [0.07825915818812121],\n",
    "  'gru_bias_reg': [9.370609019263161e-08],\n",
    "  'gru_dim': [452.0],\n",
    "  'gru_kernel_reg': [1.1699932655152522e-09],\n",
    "  'gru_recc_reg': [1.118300667865804e-06],\n",
    "  'lr1': [0.0009194436554174992],\n",
    "  'lr2': [0.00011484392164348851],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [0],\n",
    "  'spatial_drop': [0.3127687159502792]},\n",
    " {'batch_size': [41.0],\n",
    "  'bidirectional': [1],\n",
    "  'dense_dim': [888.0],\n",
    "  'dropout': [0.18388910768345024],\n",
    "  'gru_bias_reg': [1.0198714543301587e-08],\n",
    "  'gru_dim': [322.0],\n",
    "  'gru_kernel_reg': [4.3029409259060245e-08],\n",
    "  'gru_recc_reg': [3.1764731171976037e-06],\n",
    "  'lr1': [0.0017624941021206772],\n",
    "  'lr2': [0.0006933312845721429],\n",
    "  'mask_zero': [1],\n",
    "  'optimizer': [0],\n",
    "  'pool_type': [3],\n",
    "  'spatial_drop': [0.3120345974541232]}\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.988271 \n",
      "\n",
      "151592/151592 [==============================] - 95s 629us/step - loss: 0.0525 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9839\n",
      " ROC-AUC - epoch: 2 - score: 0.989440 \n",
      "\n",
      "151592/151592 [==============================] - 96s 635us/step - loss: 0.0415 - acc: 0.9839\n",
      "Epoch 3/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9844\n",
      " ROC-AUC - epoch: 3 - score: 0.990099 \n",
      "\n",
      "151592/151592 [==============================] - 96s 633us/step - loss: 0.0400 - acc: 0.9844\n",
      "Epoch 4/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9848\n",
      " ROC-AUC - epoch: 4 - score: 0.990488 \n",
      "\n",
      "151592/151592 [==============================] - 96s 637us/step - loss: 0.0387 - acc: 0.9848\n",
      "Epoch 5/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9850\n",
      " ROC-AUC - epoch: 5 - score: 0.990278 \n",
      "\n",
      "151592/151592 [==============================] - 96s 634us/step - loss: 0.0375 - acc: 0.9850\n",
      "ROC AUC for this fold is  0.990278184376726\n",
      "Epoch 1/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9810\n",
      " ROC-AUC - epoch: 1 - score: 0.987985 \n",
      "\n",
      "151592/151592 [==============================] - 95s 629us/step - loss: 0.0523 - acc: 0.9810\n",
      "Epoch 2/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9840\n",
      " ROC-AUC - epoch: 2 - score: 0.989558 \n",
      "\n",
      "151592/151592 [==============================] - 95s 629us/step - loss: 0.0413 - acc: 0.9840\n",
      "Epoch 3/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9846\n",
      " ROC-AUC - epoch: 3 - score: 0.989969 \n",
      "\n",
      "151592/151592 [==============================] - 95s 629us/step - loss: 0.0395 - acc: 0.9846\n",
      "Epoch 4/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9849\n",
      " ROC-AUC - epoch: 4 - score: 0.989952 \n",
      "\n",
      "151592/151592 [==============================] - 95s 628us/step - loss: 0.0385 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9852\n",
      " ROC-AUC - epoch: 5 - score: 0.989465 \n",
      "\n",
      "151592/151592 [==============================] - 95s 629us/step - loss: 0.0375 - acc: 0.9852\n",
      "ROC AUC for this fold is  0.9894650710770194\n",
      "Epoch 1/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.986376 \n",
      "\n",
      "151592/151592 [==============================] - 95s 629us/step - loss: 0.0529 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9840\n",
      " ROC-AUC - epoch: 2 - score: 0.988095 \n",
      "\n",
      "151592/151592 [==============================] - 95s 628us/step - loss: 0.0413 - acc: 0.9840\n",
      "Epoch 3/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9845\n",
      " ROC-AUC - epoch: 3 - score: 0.988792 \n",
      "\n",
      "151592/151592 [==============================] - 95s 628us/step - loss: 0.0397 - acc: 0.9845\n",
      "Epoch 4/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9849\n",
      " ROC-AUC - epoch: 4 - score: 0.989406 \n",
      "\n",
      "151592/151592 [==============================] - 95s 628us/step - loss: 0.0384 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9853\n",
      " ROC-AUC - epoch: 5 - score: 0.989219 \n",
      "\n",
      "151592/151592 [==============================] - 95s 628us/step - loss: 0.0374 - acc: 0.9853\n",
      "ROC AUC for this fold is  0.9892188842059451\n",
      "Epoch 1/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9811\n",
      " ROC-AUC - epoch: 1 - score: 0.989085 \n",
      "\n",
      "151592/151592 [==============================] - 95s 627us/step - loss: 0.0518 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9839\n",
      " ROC-AUC - epoch: 2 - score: 0.990208 \n",
      "\n",
      "151592/151592 [==============================] - 95s 628us/step - loss: 0.0412 - acc: 0.9840\n",
      "Epoch 3/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9844\n",
      " ROC-AUC - epoch: 3 - score: 0.990803 \n",
      "\n",
      "151592/151592 [==============================] - 95s 626us/step - loss: 0.0397 - acc: 0.9844\n",
      "Epoch 4/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9849\n",
      " ROC-AUC - epoch: 4 - score: 0.991040 \n",
      "\n",
      "151592/151592 [==============================] - 95s 627us/step - loss: 0.0385 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9852\n",
      " ROC-AUC - epoch: 5 - score: 0.991134 \n",
      "\n",
      "151592/151592 [==============================] - 95s 627us/step - loss: 0.0375 - acc: 0.9852\n",
      "ROC AUC for this fold is  0.9911340533022854\n",
      "Epoch 1/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9810\n",
      " ROC-AUC - epoch: 1 - score: 0.988642 \n",
      "\n",
      "151592/151592 [==============================] - 95s 627us/step - loss: 0.0522 - acc: 0.9810\n",
      "Epoch 2/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9840\n",
      " ROC-AUC - epoch: 2 - score: 0.990059 \n",
      "\n",
      "151592/151592 [==============================] - 94s 622us/step - loss: 0.0413 - acc: 0.9840\n",
      "Epoch 3/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9845\n",
      " ROC-AUC - epoch: 3 - score: 0.990342 \n",
      "\n",
      "151592/151592 [==============================] - 94s 622us/step - loss: 0.0397 - acc: 0.9845\n",
      "Epoch 4/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9849\n",
      " ROC-AUC - epoch: 4 - score: 0.990522 \n",
      "\n",
      "151592/151592 [==============================] - 94s 621us/step - loss: 0.0386 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9852\n",
      " ROC-AUC - epoch: 5 - score: 0.990502 \n",
      "\n",
      "151592/151592 [==============================] - 94s 621us/step - loss: 0.0375 - acc: 0.9852\n",
      "ROC AUC for this fold is  0.9905017312217789\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [1.9638193e-01 1.4239868e-06 2.9173991e-01 ... 2.0603979e-05 1.2974370e-04\n",
      " 1.0796924e-03] and [7.1238589e-01 3.4519129e-05 3.3648186e-05 ... 1.5500424e-04 3.8116914e-04\n",
      " 3.9489493e-01]\n",
      "Overall score on 10 fold CV is 0.9898627004643162\n",
      "Epoch 1/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9811\n",
      " ROC-AUC - epoch: 1 - score: 0.987469 \n",
      "\n",
      "151592/151592 [==============================] - 83s 551us/step - loss: 0.0509 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9845\n",
      " ROC-AUC - epoch: 2 - score: 0.990219 \n",
      "\n",
      "151592/151592 [==============================] - 84s 553us/step - loss: 0.0394 - acc: 0.9845\n",
      "Epoch 3/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9851\n",
      " ROC-AUC - epoch: 3 - score: 0.990532 \n",
      "\n",
      "151592/151592 [==============================] - 84s 554us/step - loss: 0.0377 - acc: 0.9851\n",
      "Epoch 4/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9856\n",
      " ROC-AUC - epoch: 4 - score: 0.990552 \n",
      "\n",
      "151592/151592 [==============================] - 84s 553us/step - loss: 0.0360 - acc: 0.9856\n",
      "Epoch 5/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9863\n",
      " ROC-AUC - epoch: 5 - score: 0.990565 \n",
      "\n",
      "151592/151592 [==============================] - 84s 553us/step - loss: 0.0343 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9905645633735062\n",
      "Epoch 1/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.987009 \n",
      "\n",
      "151592/151592 [==============================] - 84s 555us/step - loss: 0.0519 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.989421 \n",
      "\n",
      "151592/151592 [==============================] - 84s 552us/step - loss: 0.0400 - acc: 0.9844\n",
      "Epoch 3/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9849\n",
      " ROC-AUC - epoch: 3 - score: 0.989914 \n",
      "\n",
      "151592/151592 [==============================] - 84s 552us/step - loss: 0.0381 - acc: 0.9849\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9855\n",
      " ROC-AUC - epoch: 4 - score: 0.989688 \n",
      "\n",
      "151592/151592 [==============================] - 83s 548us/step - loss: 0.0364 - acc: 0.9855\n",
      "Epoch 5/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9861\n",
      " ROC-AUC - epoch: 5 - score: 0.989924 \n",
      "\n",
      "151592/151592 [==============================] - 83s 549us/step - loss: 0.0347 - acc: 0.9861\n",
      "ROC AUC for this fold is  0.9899235072051001\n",
      "Epoch 1/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.985469 \n",
      "\n",
      "151592/151592 [==============================] - 83s 550us/step - loss: 0.0508 - acc: 0.9814\n",
      "Epoch 2/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9845\n",
      " ROC-AUC - epoch: 2 - score: 0.986570 \n",
      "\n",
      "151592/151592 [==============================] - 83s 548us/step - loss: 0.0394 - acc: 0.9845\n",
      "Epoch 3/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.987546 \n",
      "\n",
      "151592/151592 [==============================] - 83s 548us/step - loss: 0.0376 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9857\n",
      " ROC-AUC - epoch: 4 - score: 0.988261 \n",
      "\n",
      "151592/151592 [==============================] - 83s 548us/step - loss: 0.0359 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9864\n",
      " ROC-AUC - epoch: 5 - score: 0.988102 \n",
      "\n",
      "151592/151592 [==============================] - 83s 548us/step - loss: 0.0343 - acc: 0.9864\n",
      "ROC AUC for this fold is  0.9881018769615434\n",
      "Epoch 1/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.987986 \n",
      "\n",
      "151592/151592 [==============================] - 83s 549us/step - loss: 0.0514 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.990316 \n",
      "\n",
      "151592/151592 [==============================] - 83s 548us/step - loss: 0.0399 - acc: 0.9844\n",
      "Epoch 3/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.990834 \n",
      "\n",
      "151592/151592 [==============================] - 83s 549us/step - loss: 0.0379 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9858\n",
      " ROC-AUC - epoch: 4 - score: 0.991103 \n",
      "\n",
      "151592/151592 [==============================] - 83s 549us/step - loss: 0.0360 - acc: 0.9858\n",
      "Epoch 5/5\n",
      "151558/151592 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9863\n",
      " ROC-AUC - epoch: 5 - score: 0.991371 \n",
      "\n",
      "151592/151592 [==============================] - 83s 549us/step - loss: 0.0345 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9913705992266468\n",
      "Epoch 1/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.987637 \n",
      "\n",
      "151592/151592 [==============================] - 83s 551us/step - loss: 0.0502 - acc: 0.9814\n",
      "Epoch 2/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9845\n",
      " ROC-AUC - epoch: 2 - score: 0.989075 \n",
      "\n",
      "151592/151592 [==============================] - 83s 549us/step - loss: 0.0397 - acc: 0.9845\n",
      "Epoch 3/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.989693 \n",
      "\n",
      "151592/151592 [==============================] - 83s 549us/step - loss: 0.0379 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9857\n",
      " ROC-AUC - epoch: 4 - score: 0.989807 \n",
      "\n",
      "151592/151592 [==============================] - 83s 550us/step - loss: 0.0360 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "151475/151592 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9862\n",
      " ROC-AUC - epoch: 5 - score: 0.989521 \n",
      "\n",
      "151592/151592 [==============================] - 83s 550us/step - loss: 0.0344 - acc: 0.9862\n",
      "ROC AUC for this fold is  0.9895208924731769\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [2.2861791e-01 1.3621190e-06 1.7215574e-01 ... 2.0940385e-04 1.9075390e-04\n",
      " 2.4625806e-03] and [6.9776899e-01 1.4865480e-05 5.2802648e-06 ... 5.0739342e-05 1.6246618e-04\n",
      " 4.0085879e-01]\n",
      "Overall score on 10 fold CV is 0.9896626982816303\n",
      "Epoch 1/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.987568 \n",
      "\n",
      "151592/151592 [==============================] - 106s 698us/step - loss: 0.0507 - acc: 0.9813\n",
      "Epoch 2/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.989040 \n",
      "\n",
      "151592/151592 [==============================] - 106s 696us/step - loss: 0.0400 - acc: 0.9843\n",
      "Epoch 3/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9847\n",
      " ROC-AUC - epoch: 3 - score: 0.989431 \n",
      "\n",
      "151592/151592 [==============================] - 105s 695us/step - loss: 0.0387 - acc: 0.9847\n",
      "Epoch 4/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9850\n",
      " ROC-AUC - epoch: 4 - score: 0.989879 \n",
      "\n",
      "151592/151592 [==============================] - 106s 697us/step - loss: 0.0379 - acc: 0.9850\n",
      "Epoch 5/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9852\n",
      " ROC-AUC - epoch: 5 - score: 0.989834 \n",
      "\n",
      "151592/151592 [==============================] - 105s 695us/step - loss: 0.0372 - acc: 0.9852\n",
      "ROC AUC for this fold is  0.9898337004568513\n",
      "Epoch 1/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9811\n",
      " ROC-AUC - epoch: 1 - score: 0.985838 \n",
      "\n",
      "151592/151592 [==============================] - 105s 694us/step - loss: 0.0516 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.989052 \n",
      "\n",
      "151592/151592 [==============================] - 105s 693us/step - loss: 0.0401 - acc: 0.9843\n",
      "Epoch 3/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9846\n",
      " ROC-AUC - epoch: 3 - score: 0.989560 \n",
      "\n",
      "151592/151592 [==============================] - 105s 692us/step - loss: 0.0389 - acc: 0.9846\n",
      "Epoch 4/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9849\n",
      " ROC-AUC - epoch: 4 - score: 0.989678 \n",
      "\n",
      "151592/151592 [==============================] - 105s 693us/step - loss: 0.0379 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9852\n",
      " ROC-AUC - epoch: 5 - score: 0.989826 \n",
      "\n",
      "151592/151592 [==============================] - 105s 692us/step - loss: 0.0372 - acc: 0.9852\n",
      "ROC AUC for this fold is  0.9898257075812541\n",
      "Epoch 1/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9810\n",
      " ROC-AUC - epoch: 1 - score: 0.984285 \n",
      "\n",
      "151592/151592 [==============================] - 105s 693us/step - loss: 0.0520 - acc: 0.9810\n",
      "Epoch 2/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.986908 \n",
      "\n",
      "151592/151592 [==============================] - 105s 692us/step - loss: 0.0403 - acc: 0.9842\n",
      "Epoch 3/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9846\n",
      " ROC-AUC - epoch: 3 - score: 0.987740 \n",
      "\n",
      "151592/151592 [==============================] - 105s 692us/step - loss: 0.0391 - acc: 0.9846\n",
      "Epoch 4/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9847\n",
      " ROC-AUC - epoch: 4 - score: 0.988099 \n",
      "\n",
      "151592/151592 [==============================] - 105s 693us/step - loss: 0.0384 - acc: 0.9847\n",
      "Epoch 5/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9850\n",
      " ROC-AUC - epoch: 5 - score: 0.988432 \n",
      "\n",
      "151592/151592 [==============================] - 105s 692us/step - loss: 0.0377 - acc: 0.9850\n",
      "ROC AUC for this fold is  0.9884322976781368\n",
      "Epoch 1/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9812\n",
      " ROC-AUC - epoch: 1 - score: 0.988419 \n",
      "\n",
      "151592/151592 [==============================] - 106s 697us/step - loss: 0.0512 - acc: 0.9812\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.990195 \n",
      "\n",
      "151592/151592 [==============================] - 105s 695us/step - loss: 0.0405 - acc: 0.9842\n",
      "Epoch 3/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9844\n",
      " ROC-AUC - epoch: 3 - score: 0.990138 \n",
      "\n",
      "151592/151592 [==============================] - 105s 694us/step - loss: 0.0393 - acc: 0.9844\n",
      "Epoch 4/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9846\n",
      " ROC-AUC - epoch: 4 - score: 0.990442 \n",
      "\n",
      "151592/151592 [==============================] - 105s 695us/step - loss: 0.0386 - acc: 0.9846\n",
      "Epoch 5/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9849\n",
      " ROC-AUC - epoch: 5 - score: 0.990674 \n",
      "\n",
      "151592/151592 [==============================] - 105s 696us/step - loss: 0.0378 - acc: 0.9849\n",
      "ROC AUC for this fold is  0.9906735420612999\n",
      "Epoch 1/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.988000 \n",
      "\n",
      "151592/151592 [==============================] - 106s 697us/step - loss: 0.0515 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.989086 \n",
      "\n",
      "151592/151592 [==============================] - 106s 696us/step - loss: 0.0401 - acc: 0.9842\n",
      "Epoch 3/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9847\n",
      " ROC-AUC - epoch: 3 - score: 0.989631 \n",
      "\n",
      "151592/151592 [==============================] - 105s 695us/step - loss: 0.0387 - acc: 0.9847\n",
      "Epoch 4/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9849\n",
      " ROC-AUC - epoch: 4 - score: 0.989837 \n",
      "\n",
      "151592/151592 [==============================] - 105s 695us/step - loss: 0.0378 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "151557/151592 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9851\n",
      " ROC-AUC - epoch: 5 - score: 0.989856 \n",
      "\n",
      "151592/151592 [==============================] - 105s 695us/step - loss: 0.0373 - acc: 0.9851\n",
      "ROC AUC for this fold is  0.9898562020250997\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [1.9118090e-01 6.5650656e-06 2.7719328e-01 ... 3.4689543e-05 4.8451344e-04\n",
      " 5.9451890e-04] and [7.0314580e-01 4.7876467e-05 5.1864703e-05 ... 1.8435554e-05 2.8027338e-04\n",
      " 3.8648781e-01]\n",
      "Overall score on 10 fold CV is 0.989678491115494\n",
      "Epoch 1/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9808\n",
      " ROC-AUC - epoch: 1 - score: 0.987633 \n",
      "\n",
      "151592/151592 [==============================] - 76s 501us/step - loss: 0.0533 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.989374 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0430 - acc: 0.9836\n",
      "Epoch 3/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9840\n",
      " ROC-AUC - epoch: 3 - score: 0.989658 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0415 - acc: 0.9840\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9842\n",
      " ROC-AUC - epoch: 4 - score: 0.990146 \n",
      "\n",
      "151592/151592 [==============================] - 76s 499us/step - loss: 0.0406 - acc: 0.9842\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9845\n",
      " ROC-AUC - epoch: 5 - score: 0.990087 \n",
      "\n",
      "151592/151592 [==============================] - 76s 499us/step - loss: 0.0399 - acc: 0.9845\n",
      "ROC AUC for this fold is  0.9900867853780486\n",
      "Epoch 1/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9806\n",
      " ROC-AUC - epoch: 1 - score: 0.988162 \n",
      "\n",
      "151592/151592 [==============================] - 76s 502us/step - loss: 0.0540 - acc: 0.9806\n",
      "Epoch 2/5\n",
      "151495/151592 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.989008 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0431 - acc: 0.9836\n",
      "Epoch 3/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9839\n",
      " ROC-AUC - epoch: 3 - score: 0.989869 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0417 - acc: 0.9839\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9843\n",
      " ROC-AUC - epoch: 4 - score: 0.990097 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0408 - acc: 0.9843\n",
      "Epoch 5/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9845\n",
      " ROC-AUC - epoch: 5 - score: 0.990183 \n",
      "\n",
      "151592/151592 [==============================] - 76s 499us/step - loss: 0.0399 - acc: 0.9845\n",
      "ROC AUC for this fold is  0.9901831794350269\n",
      "Epoch 1/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9807\n",
      " ROC-AUC - epoch: 1 - score: 0.983790 \n",
      "\n",
      "151592/151592 [==============================] - 76s 502us/step - loss: 0.0535 - acc: 0.9807\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9835\n",
      " ROC-AUC - epoch: 2 - score: 0.986954 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0433 - acc: 0.9835\n",
      "Epoch 3/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9840\n",
      " ROC-AUC - epoch: 3 - score: 0.987196 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0417 - acc: 0.9840\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9841\n",
      " ROC-AUC - epoch: 4 - score: 0.987841 \n",
      "\n",
      "151592/151592 [==============================] - 76s 499us/step - loss: 0.0410 - acc: 0.9841\n",
      "Epoch 5/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9844\n",
      " ROC-AUC - epoch: 5 - score: 0.987468 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0403 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.9874677604041762\n",
      "Epoch 1/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9806\n",
      " ROC-AUC - epoch: 1 - score: 0.987249 \n",
      "\n",
      "151592/151592 [==============================] - 76s 502us/step - loss: 0.0544 - acc: 0.9806\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9834\n",
      " ROC-AUC - epoch: 2 - score: 0.989168 \n",
      "\n",
      "151592/151592 [==============================] - 76s 501us/step - loss: 0.0436 - acc: 0.9834\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9837\n",
      " ROC-AUC - epoch: 3 - score: 0.989859 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0421 - acc: 0.9837\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9842\n",
      " ROC-AUC - epoch: 4 - score: 0.990212 \n",
      "\n",
      "151592/151592 [==============================] - 76s 502us/step - loss: 0.0412 - acc: 0.9842\n",
      "Epoch 5/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9843\n",
      " ROC-AUC - epoch: 5 - score: 0.990508 \n",
      "\n",
      "151592/151592 [==============================] - 76s 501us/step - loss: 0.0404 - acc: 0.9843\n",
      "ROC AUC for this fold is  0.9905077442392548\n",
      "Epoch 1/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9806\n",
      " ROC-AUC - epoch: 1 - score: 0.987816 \n",
      "\n",
      "151592/151592 [==============================] - 76s 503us/step - loss: 0.0541 - acc: 0.9806\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.988990 \n",
      "\n",
      "151592/151592 [==============================] - 76s 500us/step - loss: 0.0430 - acc: 0.9836\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9841\n",
      " ROC-AUC - epoch: 3 - score: 0.989352 \n",
      "\n",
      "151592/151592 [==============================] - 76s 502us/step - loss: 0.0416 - acc: 0.9841\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9843\n",
      " ROC-AUC - epoch: 4 - score: 0.989555 \n",
      "\n",
      "151592/151592 [==============================] - 76s 502us/step - loss: 0.0406 - acc: 0.9843\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9846\n",
      " ROC-AUC - epoch: 5 - score: 0.989743 \n",
      "\n",
      "151592/151592 [==============================] - 76s 502us/step - loss: 0.0400 - acc: 0.9846\n",
      "ROC AUC for this fold is  0.9897431146144707\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [2.1985795e-01 1.8366880e-05 3.3459386e-01 ... 6.8765868e-05 3.7406789e-04\n",
      " 4.7276661e-04] and [7.3218870e-01 9.3206800e-05 1.1844366e-04 ... 5.5521086e-05 6.5178750e-04\n",
      " 3.9143741e-01]\n",
      "Overall score on 10 fold CV is 0.9894736728787645\n",
      "Epoch 1/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.988015 \n",
      "\n",
      "151592/151592 [==============================] - 126s 831us/step - loss: 0.0511 - acc: 0.9813\n",
      "Epoch 2/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.989966 \n",
      "\n",
      "151592/151592 [==============================] - 126s 830us/step - loss: 0.0405 - acc: 0.9843\n",
      "Epoch 3/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9849\n",
      " ROC-AUC - epoch: 3 - score: 0.990436 \n",
      "\n",
      "151592/151592 [==============================] - 126s 830us/step - loss: 0.0387 - acc: 0.9849\n",
      "Epoch 4/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9854\n",
      " ROC-AUC - epoch: 4 - score: 0.990622 \n",
      "\n",
      "151592/151592 [==============================] - 126s 829us/step - loss: 0.0374 - acc: 0.9854\n",
      "Epoch 5/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9857\n",
      " ROC-AUC - epoch: 5 - score: 0.990781 \n",
      "\n",
      "151592/151592 [==============================] - 126s 830us/step - loss: 0.0364 - acc: 0.9857\n",
      "ROC AUC for this fold is  0.990780543449331\n",
      "Epoch 1/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.988842 \n",
      "\n",
      "151592/151592 [==============================] - 127s 835us/step - loss: 0.0511 - acc: 0.9814\n",
      "Epoch 2/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.990045 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0405 - acc: 0.9843\n",
      "Epoch 3/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.990134 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0386 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9854\n",
      " ROC-AUC - epoch: 4 - score: 0.990652 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0372 - acc: 0.9854\n",
      "Epoch 5/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9858\n",
      " ROC-AUC - epoch: 5 - score: 0.990464 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0362 - acc: 0.9858\n",
      "ROC AUC for this fold is  0.9904637530707019\n",
      "Epoch 1/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.983470 \n",
      "\n",
      "151592/151592 [==============================] - 127s 835us/step - loss: 0.0511 - acc: 0.9814\n",
      "Epoch 2/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.987636 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0406 - acc: 0.9843\n",
      "Epoch 3/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9849\n",
      " ROC-AUC - epoch: 3 - score: 0.988024 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0389 - acc: 0.9849\n",
      "Epoch 4/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9853\n",
      " ROC-AUC - epoch: 4 - score: 0.988777 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0374 - acc: 0.9853\n",
      "Epoch 5/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9856\n",
      " ROC-AUC - epoch: 5 - score: 0.989139 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0363 - acc: 0.9856\n",
      "ROC AUC for this fold is  0.9891386844487768\n",
      "Epoch 1/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.988830 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0513 - acc: 0.9814\n",
      "Epoch 2/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.990456 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0409 - acc: 0.9843\n",
      "Epoch 3/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9848\n",
      " ROC-AUC - epoch: 3 - score: 0.990599 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0389 - acc: 0.9848\n",
      "Epoch 4/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9852\n",
      " ROC-AUC - epoch: 4 - score: 0.991051 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0376 - acc: 0.9852\n",
      "Epoch 5/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9856\n",
      " ROC-AUC - epoch: 5 - score: 0.990937 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0364 - acc: 0.9856\n",
      "ROC AUC for this fold is  0.9909367227237982\n",
      "Epoch 1/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9814\n",
      " ROC-AUC - epoch: 1 - score: 0.988152 \n",
      "\n",
      "151592/151592 [==============================] - 127s 835us/step - loss: 0.0512 - acc: 0.9814\n",
      "Epoch 2/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.989253 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0405 - acc: 0.9844\n",
      "Epoch 3/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9849\n",
      " ROC-AUC - epoch: 3 - score: 0.989439 \n",
      "\n",
      "151592/151592 [==============================] - 126s 833us/step - loss: 0.0387 - acc: 0.9849\n",
      "Epoch 4/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9853\n",
      " ROC-AUC - epoch: 4 - score: 0.989039 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0374 - acc: 0.9853\n",
      "Epoch 5/5\n",
      "151589/151592 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9857\n",
      " ROC-AUC - epoch: 5 - score: 0.989348 \n",
      "\n",
      "151592/151592 [==============================] - 126s 834us/step - loss: 0.0363 - acc: 0.9857\n",
      "ROC AUC for this fold is  0.9893483559959918\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [2.1966338e-01 1.4271754e-06 2.8129336e-01 ... 4.0571522e-05 3.3966082e-04\n",
      " 5.6211662e-04] and [7.0219821e-01 2.8724682e-05 3.5231627e-05 ... 4.6861645e-05 1.7367008e-04\n",
      " 3.8507834e-01]\n",
      "Overall score on 10 fold CV is 0.9898870088325679\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9805\n",
      " ROC-AUC - epoch: 1 - score: 0.987473 \n",
      "\n",
      "151592/151592 [==============================] - 158s 1ms/step - loss: 0.0542 - acc: 0.9805\n",
      "Epoch 2/5\n",
      "151584/151592 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9833\n",
      " ROC-AUC - epoch: 2 - score: 0.989329 \n",
      "\n",
      "151592/151592 [==============================] - 158s 1ms/step - loss: 0.0437 - acc: 0.9833\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9840\n",
      " ROC-AUC - epoch: 3 - score: 0.989677 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0414 - acc: 0.9840\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9842\n",
      " ROC-AUC - epoch: 4 - score: 0.989893 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0406 - acc: 0.9842\n",
      "Epoch 5/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9845\n",
      " ROC-AUC - epoch: 5 - score: 0.990018 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0397 - acc: 0.9845\n",
      "ROC AUC for this fold is  0.99001845654342\n",
      "Epoch 1/5\n",
      "151584/151592 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9808\n",
      " ROC-AUC - epoch: 1 - score: 0.986491 \n",
      "\n",
      "151592/151592 [==============================] - 158s 1ms/step - loss: 0.0537 - acc: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.989051 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0430 - acc: 0.9836\n",
      "Epoch 3/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9841\n",
      " ROC-AUC - epoch: 3 - score: 0.989155 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0413 - acc: 0.9841\n",
      "Epoch 4/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9844\n",
      " ROC-AUC - epoch: 4 - score: 0.989834 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0402 - acc: 0.9844\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9847\n",
      " ROC-AUC - epoch: 5 - score: 0.990148 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0392 - acc: 0.9847\n",
      "ROC AUC for this fold is  0.9901482212505526\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9806\n",
      " ROC-AUC - epoch: 1 - score: 0.984931 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0545 - acc: 0.9806\n",
      "Epoch 2/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9834\n",
      " ROC-AUC - epoch: 2 - score: 0.987363 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0434 - acc: 0.9834\n",
      "Epoch 3/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9840\n",
      " ROC-AUC - epoch: 3 - score: 0.988202 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0415 - acc: 0.9840\n",
      "Epoch 4/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9843\n",
      " ROC-AUC - epoch: 4 - score: 0.988174 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0405 - acc: 0.9843\n",
      "Epoch 5/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9846\n",
      " ROC-AUC - epoch: 5 - score: 0.988247 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0397 - acc: 0.9845\n",
      "ROC AUC for this fold is  0.9882468241188661\n",
      "Epoch 1/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9805\n",
      " ROC-AUC - epoch: 1 - score: 0.988833 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0544 - acc: 0.9805\n",
      "Epoch 2/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9833\n",
      " ROC-AUC - epoch: 2 - score: 0.990773 \n",
      "\n",
      "151592/151592 [==============================] - 156s 1ms/step - loss: 0.0438 - acc: 0.9833\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9838\n",
      " ROC-AUC - epoch: 3 - score: 0.990429 \n",
      "\n",
      "151592/151592 [==============================] - 156s 1ms/step - loss: 0.0420 - acc: 0.9838\n",
      "Epoch 4/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 4 - score: 0.990877 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0408 - acc: 0.9842\n",
      "Epoch 5/5\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9846\n",
      " ROC-AUC - epoch: 5 - score: 0.991160 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0399 - acc: 0.9846\n",
      "ROC AUC for this fold is  0.9911599136524378\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9805\n",
      " ROC-AUC - epoch: 1 - score: 0.985872 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0543 - acc: 0.9805\n",
      "Epoch 2/5\n",
      "151584/151592 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9834\n",
      " ROC-AUC - epoch: 2 - score: 0.989023 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0437 - acc: 0.9834\n",
      "Epoch 3/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9839\n",
      " ROC-AUC - epoch: 3 - score: 0.989020 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0418 - acc: 0.9839\n",
      "Epoch 4/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9843\n",
      " ROC-AUC - epoch: 4 - score: 0.989172 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0405 - acc: 0.9843\n",
      "Epoch 5/5\n",
      "151568/151592 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9846\n",
      " ROC-AUC - epoch: 5 - score: 0.989364 \n",
      "\n",
      "151592/151592 [==============================] - 157s 1ms/step - loss: 0.0396 - acc: 0.9846\n",
      "ROC AUC for this fold is  0.9893643437580261\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [2.2504313e-01 1.2994692e-05 3.0288616e-01 ... 6.2580561e-06 1.3496335e-04\n",
      " 3.4963575e-04] and [6.9899696e-01 5.1183819e-05 9.6974931e-05 ... 4.3610431e-05 3.4845725e-04\n",
      " 4.1312861e-01]\n",
      "Overall score on 10 fold CV is 0.989484424866914\n",
      "Epoch 1/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9811\n",
      " ROC-AUC - epoch: 1 - score: 0.989388 \n",
      "\n",
      "151592/151592 [==============================] - 48s 317us/step - loss: 0.0508 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9848\n",
      " ROC-AUC - epoch: 2 - score: 0.989587 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0382 - acc: 0.9848\n",
      "Epoch 3/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9854\n",
      " ROC-AUC - epoch: 3 - score: 0.989990 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0364 - acc: 0.9854\n",
      "Epoch 4/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9858\n",
      " ROC-AUC - epoch: 4 - score: 0.990020 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0351 - acc: 0.9858\n",
      "Epoch 5/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9864\n",
      " ROC-AUC - epoch: 5 - score: 0.990103 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0335 - acc: 0.9864\n",
      "ROC AUC for this fold is  0.9901031624969218\n",
      "Epoch 1/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.985431 \n",
      "\n",
      "151592/151592 [==============================] - 48s 317us/step - loss: 0.0515 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9848\n",
      " ROC-AUC - epoch: 2 - score: 0.988970 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0383 - acc: 0.9848\n",
      "Epoch 3/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9853\n",
      " ROC-AUC - epoch: 3 - score: 0.989648 \n",
      "\n",
      "151592/151592 [==============================] - 48s 316us/step - loss: 0.0367 - acc: 0.9853\n",
      "Epoch 4/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9858\n",
      " ROC-AUC - epoch: 4 - score: 0.989576 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0351 - acc: 0.9858\n",
      "Epoch 5/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9861\n",
      " ROC-AUC - epoch: 5 - score: 0.989555 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0337 - acc: 0.9862\n",
      "ROC AUC for this fold is  0.9895552522757353\n",
      "Epoch 1/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9812\n",
      " ROC-AUC - epoch: 1 - score: 0.985143 \n",
      "\n",
      "151592/151592 [==============================] - 48s 317us/step - loss: 0.0507 - acc: 0.9812\n",
      "Epoch 2/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9848\n",
      " ROC-AUC - epoch: 2 - score: 0.987482 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0382 - acc: 0.9848\n",
      "Epoch 3/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9853\n",
      " ROC-AUC - epoch: 3 - score: 0.987693 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0365 - acc: 0.9853\n",
      "Epoch 4/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9858\n",
      " ROC-AUC - epoch: 4 - score: 0.987430 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0351 - acc: 0.9858\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9863\n",
      " ROC-AUC - epoch: 5 - score: 0.987653 \n",
      "\n",
      "151592/151592 [==============================] - 48s 316us/step - loss: 0.0337 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9876531586364532\n",
      "Epoch 1/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.987825 \n",
      "\n",
      "151592/151592 [==============================] - 48s 315us/step - loss: 0.0511 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9848\n",
      " ROC-AUC - epoch: 2 - score: 0.989539 \n",
      "\n",
      "151592/151592 [==============================] - 48s 314us/step - loss: 0.0385 - acc: 0.9848\n",
      "Epoch 3/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9854\n",
      " ROC-AUC - epoch: 3 - score: 0.990222 \n",
      "\n",
      "151592/151592 [==============================] - 47s 313us/step - loss: 0.0366 - acc: 0.9854\n",
      "Epoch 4/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9857\n",
      " ROC-AUC - epoch: 4 - score: 0.990294 \n",
      "\n",
      "151592/151592 [==============================] - 48s 314us/step - loss: 0.0352 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9863\n",
      " ROC-AUC - epoch: 5 - score: 0.990372 \n",
      "\n",
      "151592/151592 [==============================] - 48s 313us/step - loss: 0.0336 - acc: 0.9863\n",
      "ROC AUC for this fold is  0.9903716970946413\n",
      "Epoch 1/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9811\n",
      " ROC-AUC - epoch: 1 - score: 0.985864 \n",
      "\n",
      "151592/151592 [==============================] - 48s 316us/step - loss: 0.0509 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9848\n",
      " ROC-AUC - epoch: 2 - score: 0.989731 \n",
      "\n",
      "151592/151592 [==============================] - 48s 316us/step - loss: 0.0382 - acc: 0.9848\n",
      "Epoch 3/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9853\n",
      " ROC-AUC - epoch: 3 - score: 0.990094 \n",
      "\n",
      "151592/151592 [==============================] - 48s 316us/step - loss: 0.0365 - acc: 0.9853\n",
      "Epoch 4/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9857\n",
      " ROC-AUC - epoch: 4 - score: 0.989667 \n",
      "\n",
      "151592/151592 [==============================] - 48s 316us/step - loss: 0.0353 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "151470/151592 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9862\n",
      " ROC-AUC - epoch: 5 - score: 0.989535 \n",
      "\n",
      "151592/151592 [==============================] - 48s 316us/step - loss: 0.0337 - acc: 0.9862\n",
      "ROC AUC for this fold is  0.9895351147457467\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [2.7396452e-01 6.4073902e-06 2.5150040e-01 ... 6.8276473e-05 3.1031275e-05\n",
      " 1.3266895e-03] and [7.2734410e-01 3.2940148e-05 2.6095555e-05 ... 5.0629755e-05 5.9989648e-05\n",
      " 3.8307980e-01]\n",
      "Overall score on 10 fold CV is 0.9887741150163151\n",
      "Epoch 1/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.987406 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0516 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.989950 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0395 - acc: 0.9844\n",
      "Epoch 3/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.989964 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0376 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9855\n",
      " ROC-AUC - epoch: 4 - score: 0.990530 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0359 - acc: 0.9855\n",
      "Epoch 5/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9860\n",
      " ROC-AUC - epoch: 5 - score: 0.990207 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0344 - acc: 0.9860\n",
      "ROC AUC for this fold is  0.9902071372611205\n",
      "Epoch 1/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9811\n",
      " ROC-AUC - epoch: 1 - score: 0.987379 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0511 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.989220 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0395 - acc: 0.9844\n",
      "Epoch 3/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.989930 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0376 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9856\n",
      " ROC-AUC - epoch: 4 - score: 0.990163 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0359 - acc: 0.9856\n",
      "Epoch 5/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9859\n",
      " ROC-AUC - epoch: 5 - score: 0.989812 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0344 - acc: 0.9859\n",
      "ROC AUC for this fold is  0.989811520854202\n",
      "Epoch 1/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9810\n",
      " ROC-AUC - epoch: 1 - score: 0.984378 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0512 - acc: 0.9810\n",
      "Epoch 2/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.988027 \n",
      "\n",
      "151592/151592 [==============================] - 67s 442us/step - loss: 0.0394 - acc: 0.9844\n",
      "Epoch 3/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.987972 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0376 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9856\n",
      " ROC-AUC - epoch: 4 - score: 0.989245 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0358 - acc: 0.9856\n",
      "Epoch 5/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9861\n",
      " ROC-AUC - epoch: 5 - score: 0.988808 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0342 - acc: 0.9861\n",
      "ROC AUC for this fold is  0.9888078209504759\n",
      "Epoch 1/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9808\n",
      " ROC-AUC - epoch: 1 - score: 0.987040 \n",
      "\n",
      "151592/151592 [==============================] - 67s 445us/step - loss: 0.0521 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9845\n",
      " ROC-AUC - epoch: 2 - score: 0.989198 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0397 - acc: 0.9845\n",
      "Epoch 3/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.989980 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0378 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9855\n",
      " ROC-AUC - epoch: 4 - score: 0.989908 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0363 - acc: 0.9855\n",
      "Epoch 5/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9860\n",
      " ROC-AUC - epoch: 5 - score: 0.989975 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0347 - acc: 0.9860\n",
      "ROC AUC for this fold is  0.9899750576801299\n",
      "Epoch 1/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9810\n",
      " ROC-AUC - epoch: 1 - score: 0.987630 \n",
      "\n",
      "151592/151592 [==============================] - 67s 444us/step - loss: 0.0509 - acc: 0.9810\n",
      "Epoch 2/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.989434 \n",
      "\n",
      "151592/151592 [==============================] - 67s 442us/step - loss: 0.0394 - acc: 0.9844\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9850\n",
      " ROC-AUC - epoch: 3 - score: 0.990421 \n",
      "\n",
      "151592/151592 [==============================] - 67s 442us/step - loss: 0.0375 - acc: 0.9850\n",
      "Epoch 4/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9857\n",
      " ROC-AUC - epoch: 4 - score: 0.989958 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0359 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9862\n",
      " ROC-AUC - epoch: 5 - score: 0.990450 \n",
      "\n",
      "151592/151592 [==============================] - 67s 443us/step - loss: 0.0341 - acc: 0.9862\n",
      "ROC AUC for this fold is  0.9904495203241672\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [1.9015951e-01 1.1506774e-05 2.8803870e-01 ... 4.6468806e-05 1.4614485e-03\n",
      " 7.0325827e-04] and [7.2139829e-01 1.6970062e-05 3.0218387e-06 ... 2.4934605e-05 5.1398456e-05\n",
      " 3.7478706e-01]\n",
      "Overall score on 10 fold CV is 0.9893812708111328\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.9692\n",
      " ROC-AUC - epoch: 1 - score: 0.982693 \n",
      "\n",
      "151592/151592 [==============================] - 131s 861us/step - loss: 0.4028 - acc: 0.9692\n",
      "Epoch 2/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9828\n",
      " ROC-AUC - epoch: 2 - score: 0.988494 \n",
      "\n",
      "151592/151592 [==============================] - 130s 861us/step - loss: 0.0456 - acc: 0.9828\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9836\n",
      " ROC-AUC - epoch: 3 - score: 0.989269 \n",
      "\n",
      "151592/151592 [==============================] - 130s 858us/step - loss: 0.0430 - acc: 0.9836\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9841\n",
      " ROC-AUC - epoch: 4 - score: 0.989459 \n",
      "\n",
      "151592/151592 [==============================] - 130s 859us/step - loss: 0.0416 - acc: 0.9841\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9845\n",
      " ROC-AUC - epoch: 5 - score: 0.989983 \n",
      "\n",
      "151592/151592 [==============================] - 130s 858us/step - loss: 0.0402 - acc: 0.9845\n",
      "ROC AUC for this fold is  0.9899831523748529\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9807\n",
      " ROC-AUC - epoch: 1 - score: 0.987198 \n",
      "\n",
      "151592/151592 [==============================] - 130s 858us/step - loss: 0.0542 - acc: 0.9806\n",
      "Epoch 2/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9839\n",
      " ROC-AUC - epoch: 2 - score: 0.989119 \n",
      "\n",
      "151592/151592 [==============================] - 130s 856us/step - loss: 0.0426 - acc: 0.9839\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9844\n",
      " ROC-AUC - epoch: 3 - score: 0.989408 \n",
      "\n",
      "151592/151592 [==============================] - 130s 854us/step - loss: 0.0407 - acc: 0.9844\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9849\n",
      " ROC-AUC - epoch: 4 - score: 0.989692 \n",
      "\n",
      "151592/151592 [==============================] - 130s 858us/step - loss: 0.0395 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9851\n",
      " ROC-AUC - epoch: 5 - score: 0.990014 \n",
      "\n",
      "151592/151592 [==============================] - 130s 857us/step - loss: 0.0385 - acc: 0.9852\n",
      "ROC AUC for this fold is  0.9900138989958448\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.9691\n",
      " ROC-AUC - epoch: 1 - score: 0.661432 \n",
      "\n",
      "151592/151592 [==============================] - 130s 859us/step - loss: 0.4073 - acc: 0.9691\n",
      "Epoch 2/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.9749\n",
      " ROC-AUC - epoch: 2 - score: 0.829302 \n",
      "\n",
      "151592/151592 [==============================] - 130s 858us/step - loss: 0.3124 - acc: 0.9749\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9816\n",
      " ROC-AUC - epoch: 3 - score: 0.983454 \n",
      "\n",
      "151592/151592 [==============================] - 130s 856us/step - loss: 0.0990 - acc: 0.9816\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9832\n",
      " ROC-AUC - epoch: 4 - score: 0.984370 \n",
      "\n",
      "151592/151592 [==============================] - 130s 858us/step - loss: 0.0450 - acc: 0.9832\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9836\n",
      " ROC-AUC - epoch: 5 - score: 0.984786 \n",
      "\n",
      "151592/151592 [==============================] - 130s 859us/step - loss: 0.0436 - acc: 0.9836\n",
      "ROC AUC for this fold is  0.9847863831626501\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9798\n",
      " ROC-AUC - epoch: 1 - score: 0.983084 \n",
      "\n",
      "151592/151592 [==============================] - 130s 860us/step - loss: 0.0586 - acc: 0.9798\n",
      "Epoch 2/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9831\n",
      " ROC-AUC - epoch: 2 - score: 0.987677 \n",
      "\n",
      "151592/151592 [==============================] - 130s 859us/step - loss: 0.0466 - acc: 0.9831\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9835\n",
      " ROC-AUC - epoch: 3 - score: 0.988487 \n",
      "\n",
      "151592/151592 [==============================] - 131s 861us/step - loss: 0.0446 - acc: 0.9835\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9840\n",
      " ROC-AUC - epoch: 4 - score: 0.989740 \n",
      "\n",
      "151592/151592 [==============================] - 130s 859us/step - loss: 0.0430 - acc: 0.9840\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9844\n",
      " ROC-AUC - epoch: 5 - score: 0.990295 \n",
      "\n",
      "151592/151592 [==============================] - 131s 861us/step - loss: 0.0416 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.990294838643424\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.9647\n",
      " ROC-AUC - epoch: 1 - score: 0.966686 \n",
      "\n",
      "151592/151592 [==============================] - 131s 862us/step - loss: 0.4605 - acc: 0.9647\n",
      "Epoch 2/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9796\n",
      " ROC-AUC - epoch: 2 - score: 0.973355 \n",
      "\n",
      "151592/151592 [==============================] - 130s 861us/step - loss: 0.0578 - acc: 0.9796\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9805\n",
      " ROC-AUC - epoch: 3 - score: 0.976478 \n",
      "\n",
      "151592/151592 [==============================] - 131s 861us/step - loss: 0.0548 - acc: 0.9805\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9811\n",
      " ROC-AUC - epoch: 4 - score: 0.978299 \n",
      "\n",
      "151592/151592 [==============================] - 133s 880us/step - loss: 0.0525 - acc: 0.9811\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9817\n",
      " ROC-AUC - epoch: 5 - score: 0.979952 \n",
      "\n",
      "151592/151592 [==============================] - 133s 877us/step - loss: 0.0507 - acc: 0.9817\n",
      "ROC AUC for this fold is  0.9799521422345833\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [2.7985480e-01 6.5278346e-07 2.7760017e-01 ... 1.7214357e-05 2.8804848e-03\n",
      " 3.3975925e-04] and [6.7885494e-01 3.9423644e-04 3.1582077e-04 ... 3.2577806e-05 1.6178880e-04\n",
      " 3.5526463e-01]\n",
      "Overall score on 10 fold CV is 0.9872924106747667\n",
      "Epoch 1/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9806\n",
      " ROC-AUC - epoch: 1 - score: 0.988240 \n",
      "\n",
      "151592/151592 [==============================] - 100s 660us/step - loss: 0.0538 - acc: 0.9806\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.989430 \n",
      "\n",
      "151592/151592 [==============================] - 100s 659us/step - loss: 0.0432 - acc: 0.9836\n",
      "Epoch 3/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9840\n",
      " ROC-AUC - epoch: 3 - score: 0.990317 \n",
      "\n",
      "151592/151592 [==============================] - 100s 659us/step - loss: 0.0413 - acc: 0.9840\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9844\n",
      " ROC-AUC - epoch: 4 - score: 0.990470 \n",
      "\n",
      "151592/151592 [==============================] - 100s 662us/step - loss: 0.0402 - acc: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9848\n",
      " ROC-AUC - epoch: 5 - score: 0.990288 \n",
      "\n",
      "151592/151592 [==============================] - 100s 660us/step - loss: 0.0391 - acc: 0.9848\n",
      "ROC AUC for this fold is  0.9902877022471545\n",
      "Epoch 1/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9807\n",
      " ROC-AUC - epoch: 1 - score: 0.988244 \n",
      "\n",
      "151592/151592 [==============================] - 100s 661us/step - loss: 0.0529 - acc: 0.9807\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9837\n",
      " ROC-AUC - epoch: 2 - score: 0.989459 \n",
      "\n",
      "151592/151592 [==============================] - 101s 664us/step - loss: 0.0431 - acc: 0.9837\n",
      "Epoch 3/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9840\n",
      " ROC-AUC - epoch: 3 - score: 0.989692 \n",
      "\n",
      "151592/151592 [==============================] - 101s 668us/step - loss: 0.0413 - acc: 0.9840\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9844\n",
      " ROC-AUC - epoch: 4 - score: 0.989817 \n",
      "\n",
      "151592/151592 [==============================] - 100s 661us/step - loss: 0.0402 - acc: 0.9844\n",
      "Epoch 5/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9850\n",
      " ROC-AUC - epoch: 5 - score: 0.989504 \n",
      "\n",
      "151592/151592 [==============================] - 102s 671us/step - loss: 0.0390 - acc: 0.9850\n",
      "ROC AUC for this fold is  0.9895043743279812\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9809\n",
      " ROC-AUC - epoch: 1 - score: 0.983572 \n",
      "\n",
      "151592/151592 [==============================] - 99s 655us/step - loss: 0.0533 - acc: 0.9809\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9837\n",
      " ROC-AUC - epoch: 2 - score: 0.987765 \n",
      "\n",
      "151592/151592 [==============================] - 100s 661us/step - loss: 0.0431 - acc: 0.9837\n",
      "Epoch 3/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9842\n",
      " ROC-AUC - epoch: 3 - score: 0.988306 \n",
      "\n",
      "151592/151592 [==============================] - 99s 653us/step - loss: 0.0411 - acc: 0.9842\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9846\n",
      " ROC-AUC - epoch: 4 - score: 0.989109 \n",
      "\n",
      "151592/151592 [==============================] - 97s 640us/step - loss: 0.0399 - acc: 0.9846\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9849\n",
      " ROC-AUC - epoch: 5 - score: 0.988499 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0391 - acc: 0.9849\n",
      "ROC AUC for this fold is  0.988499150803626\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9808\n",
      " ROC-AUC - epoch: 1 - score: 0.988500 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0540 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9837\n",
      " ROC-AUC - epoch: 2 - score: 0.989828 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0430 - acc: 0.9837\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9841\n",
      " ROC-AUC - epoch: 3 - score: 0.990587 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0414 - acc: 0.9841\n",
      "Epoch 4/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9845\n",
      " ROC-AUC - epoch: 4 - score: 0.990415 \n",
      "\n",
      "151592/151592 [==============================] - 97s 637us/step - loss: 0.0400 - acc: 0.9845\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9849\n",
      " ROC-AUC - epoch: 5 - score: 0.990548 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0390 - acc: 0.9849\n",
      "ROC AUC for this fold is  0.9905475220950555\n",
      "Epoch 1/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9807\n",
      " ROC-AUC - epoch: 1 - score: 0.987233 \n",
      "\n",
      "151592/151592 [==============================] - 97s 639us/step - loss: 0.0539 - acc: 0.9807\n",
      "Epoch 2/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.989442 \n",
      "\n",
      "151592/151592 [==============================] - 97s 637us/step - loss: 0.0429 - acc: 0.9836\n",
      "Epoch 3/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9842\n",
      " ROC-AUC - epoch: 3 - score: 0.989756 \n",
      "\n",
      "151592/151592 [==============================] - 97s 637us/step - loss: 0.0411 - acc: 0.9842\n",
      "Epoch 4/5\n",
      "151577/151592 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9846\n",
      " ROC-AUC - epoch: 4 - score: 0.989997 \n",
      "\n",
      "151592/151592 [==============================] - 97s 638us/step - loss: 0.0397 - acc: 0.9846\n",
      "Epoch 5/5\n",
      "151536/151592 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9851\n",
      " ROC-AUC - epoch: 5 - score: 0.989697 \n",
      "\n",
      "151592/151592 [==============================] - 97s 637us/step - loss: 0.0388 - acc: 0.9851\n",
      "ROC AUC for this fold is  0.9896969747127232\n",
      "Shape of test _preds is  (153164, 6)\n",
      "Means of val and test preds are [2.1447627e-01 3.1807354e-05 3.1675184e-01 ... 8.4409589e-04 1.3127550e-03\n",
      " 5.7867668e-03] and [6.7449313e-01 6.2541621e-05 8.3466904e-05 ... 7.7849138e-05 9.5982832e-04\n",
      " 3.9663580e-01]\n",
      "Overall score on 10 fold CV is 0.9883318680381469\n"
     ]
    }
   ],
   "source": [
    "#Pick top 10 parameter settings, Bag models for those settings\n",
    "#Try linear blending on those settings\n",
    "#NUM_BAGS = 5\n",
    "#cvlist3 = list(StratifiedShuffleSplit(n_splits=NUM_BAGS, test_size=0.05, random_state=786).split(y, y[:,2]))\n",
    "y = train[list_classes].values\n",
    "\n",
    "def shuffle_train_predict(model, cvlist, X, y, X_test, lr_decay):\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_test_preds = []\n",
    "    scores = []\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        print(\"ROC AUC for this fold is \", score)\n",
    "        y_trues.append(y_val)\n",
    "        y_preds.append(y_pred)\n",
    "        y_test_preds.append(y_test_pred)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        #break\n",
    "    y_trues = np.concatenate(y_trues)\n",
    "    y_preds = np.concatenate(y_preds)\n",
    "    y_test_preds = np.mean(y_test_preds, axis=0)\n",
    "    print(\"Shape of test _preds is \", y_test_preds.shape)\n",
    "    print(\"Means of val and test preds are {} and {}\".format(np.mean(y_preds, axis=1), np.mean(y_test_preds, axis=1)))\n",
    "    score = roc_auc_score(y_trues, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, y_test_preds\n",
    "\n",
    "def oof_train_predict(model, cvlist, X, y, X_test, lr_decay):\n",
    "    #y_trues = []\n",
    "    y_test_preds = []\n",
    "    scores = []\n",
    "    y_preds = np.zeros(y.shape)\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        print(\"ROC AUC for this fold is \", score)\n",
    "        #y_trues.append(y_val)\n",
    "        y_preds[val_index, :] = y_pred\n",
    "        y_test_preds.append(y_test_pred)\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        #break\n",
    "    #y_trues = np.concatenate(y_trues)\n",
    "    #y_preds = np.concatenate(y_preds)\n",
    "    y_test_preds = np.mean(y_test_preds, axis=0)\n",
    "    print(\"Shape of test _preds is \", y_test_preds.shape)\n",
    "    print(\"Means of val and test preds are {} and {}\".format(np.mean(y_preds, axis=0), np.mean(y_test_preds, axis=0)))\n",
    "    score = roc_auc_score(y, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_test_preds\n",
    "\n",
    "def train_predict(parameter_space):\n",
    "    \n",
    "    def lr_decay(epoch):\n",
    "        if epoch == 0:\n",
    "            return parameter_space['lr1'][0]\n",
    "        if epoch == 1:\n",
    "            return parameter_space['lr2'][0]\n",
    "        if epoch == 2:\n",
    "            return parameter_space['lr2'][0]\n",
    "        if epoch == 3:\n",
    "            return parameter_space['lr2'][0]\n",
    "        if epoch == 4:\n",
    "            return parameter_space['lr2'][0]\n",
    "        if epoch == 5:\n",
    "            return parameter_space['lr2'][0]\n",
    "    \n",
    "    model = GRUClassifier(initial_weights=embedding_matrix, bidirectional=[True, False][parameter_space['bidirectional'][0]],\n",
    "                          gru_dim = int(parameter_space['gru_dim'][0]),\n",
    "                          dense_dim = int(parameter_space['dense_dim'][0]),\n",
    "                          mask_zero = [True, False][parameter_space['mask_zero'][0]],\n",
    "                          pool_type = ['avg', 'max', 'attn', 'all'][parameter_space['pool_type'][0]],\n",
    "                          batch_size= int(parameter_space['batch_size'][0]), \n",
    "                          epochs=5,\n",
    "                          optimizer=[\"adam\", \"rmsprop\"][parameter_space['optimizer'][0]],\n",
    "                          dropout=parameter_space['dropout'][0],\n",
    "                          spatial_drop=parameter_space['spatial_drop'][0],\n",
    "                          gru_kernel_regularization = parameter_space[\"gru_kernel_reg\"][0],\n",
    "                          gru_recurrent_regularization = parameter_space[\"gru_recc_reg\"][0],\n",
    "                          gru_bias_regularization = parameter_space[\"gru_bias_reg\"][0],\n",
    "                          #embeddings_regularization = parameter_space[\"embeddings_reg\"],\n",
    "                          )\n",
    "\n",
    "    y_preds, y_trues, y_test_preds = shuffle_train_predict(model, cvlist2, X_train, y, X_test, lr_decay) \n",
    "    #y_preds, y_test_preds = shuffle_train_predict(model, cvlist2, X_train, y, X_test, lr_decay)\n",
    "    return y_preds, y_trues, y_test_preds\n",
    "\n",
    "#####\n",
    "y_preds_all = []\n",
    "y_trues_all = []\n",
    "y_test_preds_all = []\n",
    "for params in parameter_list:\n",
    "    y_preds, y_trues, y_test_preds = train_predict(params)\n",
    "    y_preds_all.append(y_preds)\n",
    "    y_trues_all.append(y_trues)\n",
    "    y_test_preds_all.append(y_test_preds)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.98016906],\n",
       "       [0.98016906, 1.        ]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check corelation between different predictions\n",
    "np.corrcoef(y_preds_all[0][:,0], y_preds_all[1][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.79079080e-01, 9.86868516e-03, 1.08758599e-01, 2.11035367e-03,\n",
       "         1.91006184e-01, 2.80884445e-01],\n",
       "        [6.97876294e-06, 1.41036482e-09, 1.00620821e-06, 2.39269671e-08,\n",
       "         1.57298246e-07, 5.10783993e-09],\n",
       "        [7.22955167e-01, 3.86204221e-03, 2.47543510e-02, 8.58226034e-04,\n",
       "         1.13805935e-01, 1.66698694e-01],\n",
       "        ...,\n",
       "        [1.14090135e-03, 8.08621508e-07, 9.11738389e-05, 2.93071548e-06,\n",
       "         8.42992813e-06, 1.21785797e-05],\n",
       "        [7.08651263e-04, 5.32397848e-07, 3.23111948e-04, 7.07196435e-08,\n",
       "         7.75570297e-05, 3.46000852e-05],\n",
       "        [1.27295144e-02, 7.17958937e-06, 1.12834608e-03, 7.01096178e-06,\n",
       "         7.89984944e-04, 1.13448048e-04]],\n",
       "\n",
       "       [[6.53501987e-01, 1.20655801e-02, 7.93245658e-02, 9.36802477e-03,\n",
       "         1.79860622e-01, 3.85026962e-01],\n",
       "        [7.26245999e-05, 2.80117433e-07, 3.13615710e-05, 4.90710249e-07,\n",
       "         4.90288312e-06, 5.41392353e-07],\n",
       "        [9.27289128e-01, 1.93929393e-02, 1.15157492e-01, 3.50084575e-03,\n",
       "         3.76395583e-01, 5.65827012e-01],\n",
       "        ...,\n",
       "        [3.62691702e-04, 1.65809865e-06, 2.08383008e-05, 5.50749610e-06,\n",
       "         1.47135625e-05, 7.18604224e-06],\n",
       "        [1.61806738e-03, 9.15531564e-06, 3.99848417e-04, 1.58451553e-06,\n",
       "         1.67066610e-04, 4.86850950e-05],\n",
       "        [2.20560306e-03, 1.22901083e-05, 2.63298076e-04, 1.32940340e-05,\n",
       "         3.13204393e-04, 2.89098934e-05]],\n",
       "\n",
       "       [[8.02521169e-01, 4.93016094e-03, 2.84135491e-02, 2.06744275e-03,\n",
       "         1.47901133e-01, 3.32146853e-01],\n",
       "        [8.27266012e-06, 2.28592789e-09, 2.01262736e-07, 1.55169211e-08,\n",
       "         5.35153362e-08, 1.78116970e-08],\n",
       "        [9.13623512e-01, 1.24349352e-02, 7.73058161e-02, 7.93550222e-04,\n",
       "         2.64461756e-01, 4.19140428e-01],\n",
       "        ...,\n",
       "        [2.07530960e-04, 2.55414477e-07, 4.17637557e-06, 1.49395862e-06,\n",
       "         4.41080238e-06, 2.55616378e-05],\n",
       "        [1.73731474e-03, 1.13546946e-06, 1.72513144e-04, 3.16926446e-07,\n",
       "         7.89503538e-05, 4.77343310e-05],\n",
       "        [2.97316606e-03, 9.64973879e-07, 2.21143375e-04, 5.41059421e-07,\n",
       "         1.53462999e-04, 2.34208273e-05]],\n",
       "\n",
       "       [[6.49743855e-01, 2.17587408e-02, 6.10923693e-02, 6.24180958e-03,\n",
       "         1.88737258e-01, 4.22684729e-01],\n",
       "        [4.11152796e-05, 8.69501520e-08, 3.17378981e-05, 5.29221836e-07,\n",
       "         4.25470353e-06, 2.44097350e-07],\n",
       "        [9.02798653e-01, 1.24123935e-02, 1.22853488e-01, 1.44126813e-03,\n",
       "         3.65773648e-01, 4.12037551e-01],\n",
       "        ...,\n",
       "        [3.13251949e-05, 1.88488887e-08, 4.36097025e-06, 5.50532491e-07,\n",
       "         3.24704644e-07, 9.68088443e-07],\n",
       "        [5.85601025e-04, 2.43989604e-07, 1.87465208e-04, 2.12378865e-07,\n",
       "         3.49748552e-05, 1.28265037e-06],\n",
       "        [1.82050455e-03, 5.07912489e-07, 1.67774124e-04, 9.47841329e-07,\n",
       "         1.01395766e-04, 6.68423991e-06]],\n",
       "\n",
       "       [[8.51813793e-01, 1.49737671e-02, 8.89859125e-02, 8.60787742e-03,\n",
       "         2.53656745e-01, 4.25749123e-01],\n",
       "        [1.27557696e-05, 1.24731674e-08, 2.18199293e-05, 1.76099468e-06,\n",
       "         1.86832028e-06, 2.26854695e-07],\n",
       "        [9.04272616e-01, 5.05911978e-03, 4.77179289e-02, 1.24122750e-03,\n",
       "         2.05369100e-01, 3.45342577e-01],\n",
       "        ...,\n",
       "        [3.59836442e-04, 6.52336709e-08, 1.38218475e-05, 5.12787619e-06,\n",
       "         3.83971701e-06, 2.69677585e-05],\n",
       "        [1.45676604e-04, 3.93103150e-08, 2.40879490e-05, 3.28689794e-07,\n",
       "         4.17878164e-06, 1.18763228e-05],\n",
       "        [5.91932097e-03, 5.74503292e-06, 1.07189920e-03, 8.55913459e-06,\n",
       "         8.59015621e-04, 9.55962460e-05]]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_preds_all)[[1, 3,4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9904810037095175\n"
     ]
    }
   ],
   "source": [
    "#Try different stacking approaches\n",
    "from scipy.stats import gmean, hmean\n",
    "\n",
    "preds_mean = gmean(np.array(y_preds_all)[[0,2,3,4,5,6]] , axis=0)\n",
    "print(roc_auc_score(y_trues_all[0], preds_mean))\n",
    "test_preds_mean = gmean(np.array(y_test_preds_all)[[0, 2,3,4,5,6]], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0.9855431359864897\n",
      "severe_toxic\n",
      "0.9923104034788409\n",
      "obscene\n",
      "0.9927540190357128\n",
      "threat\n",
      "0.9939637544521266\n",
      "insult\n",
      "0.9889492486171947\n",
      "identity_hate\n",
      "0.9893654606867403\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(list_classes):\n",
    "    print(col)\n",
    "    print(roc_auc_score(y_trues_all[0][:, i], preds_mean[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mother'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmer.stem(\"mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_trues_stacked = np.concatenate(np.array(y_preds_all)[[0,2, 3,4,5,6]], axis=1)\n",
    "preds_stacked = np.concatenate(np.array(y_preds_all)[[0,2, 3,4,5,6]], axis=1)\n",
    "test_preds_stacked = np.concatenate(np.array(y_test_preds_all)[[0,2, 3,4,5,6]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [39895, 159571]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-3216d6fae1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#y_trues = train[list_classes].values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcvlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_preds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_stacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#y_preds2 =[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [39895, 159571]"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#y_trues = train[list_classes].values\n",
    "cvlist = list(StratifiedKFold(10,random_state=1).split(preds_stacked, y[:,5]))\n",
    "y_preds2 = np.zeros((preds_stacked.shape[0], len(list_classes)))\n",
    "#y_preds2 =[]\n",
    "y_test_preds2 = np.zeros((test_preds_stacked.shape[0], len(list_classes)))\n",
    "for i, col in enumerate(list_classes):\n",
    "    y_tmp = y[:, i]\n",
    "    #model = RandomForestClassifier(n_estimators=100, max_depth=6, min_samples_leaf=50, class_weight='balanced', n_jobs=-1)\n",
    "    model = lgb.LGBMClassifier(n_estimators=100, num_leaves=8, learning_rate=0.1, min_child_samples=500,\n",
    "                               subsample=0.9, colsample_bytree=0.8, reg_lambda=1.0, class_weight='balanced')\n",
    "    #model = LogisticRegression(C=0.01)\n",
    "    y_preds2[:, i] = cross_val_predict(model, preds_stacked, y_tmp, cv=cvlist, n_jobs=1, method='predict_proba')[:,1]\n",
    "    print(preds.shape)\n",
    "    #y_preds2.append(preds)\n",
    "    y_test_preds2[:, i] = model.fit(preds_stacked, y_tmp).predict_proba(test_preds_stacked)[:,1]\n",
    "    print(\"Score for class {} is {}\".format(col, roc_auc_score(y_tmp, y_preds2[:, i])))\n",
    "print(\"Over auc score\", roc_auc_score(y, y_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = test_preds_mean\n",
    "sample_submission.to_csv('../input/gru_fasttext_10bags_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22635215 0.00814813 0.13238751 0.00284009 0.09520514 0.01384137]\n",
      "[0.0891014  0.00545839 0.0506671  0.00133483 0.0458166  0.00562759]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(test_preds_mean > 0.5,axis=0))\n",
    "print(np.mean(preds_mean > 0.5, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21882427 0.00652242 0.12267243 0.00212844 0.09681126 0.01348881]\n"
     ]
    }
   ],
   "source": [
    "#belnding with public\n",
    "public_v1 = pd.read_csv(\"../input/hight_of_blend_v2.csv\")\n",
    "test_preds_mean2 = hmean([test_preds_mean, public_v1[list_classes].values], axis=0)\n",
    "print(np.mean(test_preds_mean2 > 0.5,axis=0))\n",
    "sample_submission[list_classes] = test_preds_mean2\n",
    "sample_submission.to_csv('../input/gru_fasttext_10bags_submission_wplb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990675</td>\n",
       "      <td>0.302595</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.899121</td>\n",
       "      <td>0.343316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006134</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.550533</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.028009</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.092859</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.028588</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.401750</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.110240</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.188643</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.696162</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>0.031211</td>\n",
       "      <td>0.087125</td>\n",
       "      <td>0.188482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.226343</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.015992</td>\n",
       "      <td>0.082142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.093686</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.166325</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.027694</td>\n",
       "      <td>0.115518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153134</th>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153135</th>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153136</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153137</th>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153138</th>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153139</th>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153140</th>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153142</th>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153143</th>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.155351</td>\n",
       "      <td>0.973267</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.723546</td>\n",
       "      <td>0.023123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>0.021296</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>0.770801</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.106648</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.184606</td>\n",
       "      <td>0.153817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>0.731161</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>0.277924</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.346214</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>0.328345</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.083132</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>0.809492</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.492545</td>\n",
       "      <td>0.021691</td>\n",
       "      <td>0.213481</td>\n",
       "      <td>0.003219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>0.840024</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.043887</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.113174</td>\n",
       "      <td>0.321151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>0.995155</td>\n",
       "      <td>0.177709</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.950324</td>\n",
       "      <td>0.600963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>0.007741</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>0.006447</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>0.894929</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.300858</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.699137</td>\n",
       "      <td>0.003925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>0.600626</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.181486</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.052580</td>\n",
       "      <td>0.001663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.001566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.003029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>0.638272</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.336399</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           toxic  severe_toxic   obscene    threat    insult  identity_hate\n",
       "0       0.990675      0.302595  0.966957  0.026856  0.899121       0.343316\n",
       "1       0.001449      0.000313  0.000519  0.000035  0.000688       0.000207\n",
       "2       0.003754      0.000471  0.001512  0.000137  0.001137       0.000324\n",
       "3       0.000564      0.000121  0.000271  0.000093  0.000367       0.000055\n",
       "4       0.006134      0.000244  0.001113  0.000199  0.001027       0.000144\n",
       "5       0.000919      0.000121  0.000319  0.000184  0.000764       0.000094\n",
       "6       0.003582      0.000071  0.000541  0.000048  0.001329       0.000100\n",
       "7       0.550533      0.002491  0.028009  0.001836  0.092859       0.002300\n",
       "8       0.028588      0.000160  0.005956  0.000111  0.008681       0.000373\n",
       "9       0.000655      0.000068  0.000287  0.000043  0.000508       0.000057\n",
       "10      0.401750      0.000564  0.110240  0.000342  0.014008       0.001216\n",
       "11      0.188643      0.000218  0.019480  0.000201  0.012851       0.004300\n",
       "12      0.002380      0.000069  0.000319  0.000019  0.000441       0.000050\n",
       "13      0.000713      0.000043  0.000579  0.000022  0.000419       0.000093\n",
       "14      0.000896      0.000030  0.000742  0.000009  0.000206       0.000016\n",
       "15      0.003465      0.000102  0.000517  0.000085  0.001053       0.000205\n",
       "16      0.008025      0.000507  0.002232  0.000137  0.001919       0.000695\n",
       "17      0.008424      0.000102  0.000798  0.000033  0.000931       0.000199\n",
       "18      0.000288      0.000017  0.000080  0.000005  0.000074       0.000011\n",
       "19      0.006195      0.000524  0.001361  0.000239  0.001099       0.000324\n",
       "20      0.005524      0.000454  0.001185  0.000806  0.001093       0.000356\n",
       "21      0.696162      0.005573  0.047675  0.031211  0.087125       0.188482\n",
       "22      0.226343      0.000842  0.006646  0.003576  0.015992       0.082142\n",
       "23      0.001677      0.000062  0.000424  0.000031  0.000551       0.000106\n",
       "24      0.093686      0.000294  0.011546  0.000257  0.009246       0.004287\n",
       "25      0.002697      0.000079  0.000441  0.000166  0.000810       0.000135\n",
       "26      0.001542      0.000078  0.000483  0.000118  0.000482       0.000231\n",
       "27      0.022175      0.000773  0.003761  0.000085  0.006472       0.000453\n",
       "28      0.166325      0.000798  0.005499  0.000647  0.027694       0.115518\n",
       "29      0.002332      0.000177  0.000782  0.000058  0.001339       0.000260\n",
       "...          ...           ...       ...       ...       ...            ...\n",
       "153134  0.001270      0.000059  0.000725  0.000040  0.000564       0.000103\n",
       "153135  0.001430      0.000086  0.000328  0.000046  0.000273       0.000279\n",
       "153136  0.000494      0.000021  0.000179  0.000025  0.000131       0.000040\n",
       "153137  0.020327      0.000540  0.002887  0.000690  0.004102       0.000928\n",
       "153138  0.003642      0.000075  0.000668  0.000136  0.001031       0.000356\n",
       "153139  0.001581      0.000098  0.000696  0.000015  0.000704       0.000082\n",
       "153140  0.001761      0.000105  0.000688  0.000050  0.000487       0.000109\n",
       "153141  0.001023      0.000045  0.000336  0.000034  0.000229       0.000067\n",
       "153142  0.004528      0.000239  0.000650  0.000063  0.001740       0.000622\n",
       "153143  0.994945      0.155351  0.973267  0.001724  0.723546       0.023123\n",
       "153144  0.003126      0.000276  0.000818  0.000167  0.002029       0.000242\n",
       "153145  0.001291      0.000094  0.000235  0.000032  0.000712       0.000238\n",
       "153146  0.000396      0.000069  0.000413  0.000022  0.000288       0.000036\n",
       "153147  0.003558      0.000308  0.001077  0.000063  0.001144       0.000695\n",
       "153148  0.021296      0.000234  0.001608  0.000038  0.001912       0.000982\n",
       "153149  0.770801      0.019366  0.106648  0.008138  0.184606       0.153817\n",
       "153150  0.000701      0.000044  0.000228  0.000043  0.000193       0.000046\n",
       "153151  0.731161      0.009593  0.277924  0.001576  0.346214       0.010380\n",
       "153152  0.328345      0.001262  0.083132  0.000267  0.016787       0.001384\n",
       "153153  0.809492      0.008334  0.492545  0.021691  0.213481       0.003219\n",
       "153154  0.840024      0.007512  0.043887  0.002278  0.113174       0.321151\n",
       "153155  0.995155      0.177709  0.956129  0.007294  0.950324       0.600963\n",
       "153156  0.007741      0.000169  0.001671  0.000086  0.002169       0.000515\n",
       "153157  0.006447      0.000076  0.000512  0.000020  0.001251       0.000262\n",
       "153158  0.894929      0.004003  0.300858  0.000611  0.699137       0.003925\n",
       "153159  0.600626      0.001715  0.181486  0.000731  0.052580       0.001663\n",
       "153160  0.019998      0.000463  0.003645  0.000987  0.003514       0.001566\n",
       "153161  0.000744      0.000051  0.000670  0.000027  0.000334       0.000119\n",
       "153162  0.002525      0.000109  0.000659  0.000056  0.000907       0.003029\n",
       "153163  0.961207      0.009554  0.638272  0.002233  0.336399       0.004356\n",
       "\n",
       "[153164 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_v1[list_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
