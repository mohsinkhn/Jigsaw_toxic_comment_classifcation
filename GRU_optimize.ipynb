{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GRU network with pretrained vectors for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Permute, GRU, Conv1D, LSTM, Embedding, Dropout, Activation, CuDNNLSTM, CuDNNGRU, concatenate, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, BatchNormalization, SpatialDropout1D, Dot\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from functools import reduce\n",
    "from keras.layers import Layer, PReLU, SpatialDropout1D\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, TweetTokenizer, MWETokenizer, ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "np.random.seed(786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/'\n",
    "utility_path = '../utility/'\n",
    "comp = 'jigsaw-toxic-comment-classification-challenge/'\n",
    "EMBEDDING_FILE=f'{utility_path}crawl-300d-2M.vec'\n",
    "TRAIN_DATA_FILE=f'{path}train.csv'\n",
    "TEST_DATA_FILE=f'{path}test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(series):\n",
    "    return series.apply(lambda s: unicodedata.normalize('NFKC', str(s)))\n",
    "\n",
    "\n",
    "def multiple_replace(text, adict):\n",
    "    rx = re.compile('|'.join(map(re.escape, adict)))\n",
    "\n",
    "    def one_xlat(match):\n",
    "        return adict[match.group(0)]\n",
    "\n",
    "    return rx.sub(one_xlat, text)\n",
    "\n",
    "STOP_WORDS = set(stopwords.words( 'english' ))\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(series):\n",
    "    series = unicodeToAscii(series)\n",
    "    series = series.str.lower()\n",
    "    series = series.str.replace(r\"(\\n){1,}\", \"\")\n",
    "    series = series.str.replace(r\"\\'\", \"\")\n",
    "    series = series.str.replace(r\"\\-\", \"\")\n",
    "    series = series.str.replace(r\"[^0-9a-zA-Z]+\", \" \")\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def token_generator(texts):\n",
    "    for text in texts:\n",
    "        tokens = str(text).split()\n",
    "        tokens = [token for token in tokens if token not in STOP_WORDS]\n",
    "        yield tokens\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, max_features=20000, max_len=10, tokenizer=str.split):\n",
    "        self.max_features = max_features\n",
    "        self.tokenizer = tokenizer\n",
    "        self.doc_freq = None\n",
    "        self.vocab = None\n",
    "        self.vocab_idx = None\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        tokenized = []\n",
    "        n = len(texts)\n",
    "\n",
    "        tokenized = token_generator(texts)\n",
    "        doc_freq = Counter(itertools.chain.from_iterable(tokenized))\n",
    "\n",
    "        vocab = [t[0] for t in doc_freq.most_common(self.max_features)]\n",
    "        vocab_idx = {w: (i + 1) for (i, w) in enumerate(vocab)}\n",
    "        # doc_freq = [doc_freq[t] for t in vocab]\n",
    "\n",
    "        # self.doc_freq = doc_freq\n",
    "        self.vocab = vocab\n",
    "        self.vocab_idx = vocab_idx\n",
    "\n",
    "        result_list = []\n",
    "        tokenized = token_generator(texts)\n",
    "        for text in tokenized:\n",
    "            text = self.text_to_idx(text, self.max_len)\n",
    "            result_list.append(text)\n",
    "\n",
    "        result = np.zeros(shape=(n, self.max_len), dtype=np.int32)\n",
    "        for i in range(n):\n",
    "            text = result_list[i]\n",
    "            result[i, :len(text)] = text\n",
    "\n",
    "        return result\n",
    "\n",
    "    def text_to_idx(self, tokenized, max_len):\n",
    "        return [self.vocab_idx[t] for i, t in enumerate(tokenized) if (t in self.vocab_idx) and (i < max_len)]\n",
    "\n",
    "    def transform(self, texts):\n",
    "        n = len(texts)\n",
    "        result = np.zeros(shape=(n, self.max_len), dtype=np.int32)\n",
    "\n",
    "        for i in range(n):\n",
    "            text = self.tokenizer(texts[i])\n",
    "            text = self.text_to_idx(text, self.max_len)\n",
    "            result[i, :len(text)] = text\n",
    "\n",
    "        return result\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return len(self.vocab) + 1\n",
    "\n",
    "\n",
    "def grams2(src_words):\n",
    "    return list(zip(src_words, src_words[1:]))\n",
    "\n",
    "\n",
    "def tokenizer_2gram(text):\n",
    "    return grams2(str(text).split())\n",
    "\n",
    "\n",
    "def ngrams(n, f, prune_after=10000):\n",
    "    counter = collections.Counter()\n",
    "    deque = collections.deque(maxlen=n)\n",
    "    for i, line in enumerate(f):\n",
    "        deque.clear()\n",
    "        words = str(line).split()\n",
    "        deque.extend(words[:n - 1])\n",
    "        for word in words[n - 1:]:\n",
    "            # if word in vocab:\n",
    "            deque.append(word)\n",
    "            ngram = tuple(str(w) for w in deque)\n",
    "            if i < prune_after or ngram in counter:\n",
    "                counter[ngram] += 1\n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8) (153164, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "\n",
    "#Get validation folds\n",
    "train['target_str'] = reduce(lambda x,y: x+y, [train[col].astype(str) for col in list_classes])\n",
    "train['target_str'] = train['target_str'].replace('110101', '000000').replace('110110','000000')\n",
    "cvlist1 = list(StratifiedKFold(n_splits=10, random_state=786).split(train, train['target_str'].astype('category')))\n",
    "cvlist2 = list(StratifiedShuffleSplit(n_splits=5, test_size=0.05, random_state=786).split(train, train['target_str'].astype('category')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in train, test:\n",
    "    df[\"comment_text\"] = normalizeString(df[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 250) (153164, 250)\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = 200000\n",
    "MAX_LEN = 250\n",
    "\n",
    "tok = Tokenizer(max_features=MAX_FEATURES, max_len=MAX_LEN)\n",
    "X_train = tok.fit_transform(train[\"comment_text\"].astype(str))\n",
    "X_test = tok.transform(test[\"comment_text\"].astype(str))\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 300\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def initialize_embeddings(filename, tokenizer):\n",
    "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(filename))\n",
    "\n",
    "    word_index = tokenizer.vocab_idx\n",
    "    nb_words = min(MAX_FEATURES, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= MAX_FEATURES: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 300)\n",
      "0.002500578637546975 0.2183801808372828\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = initialize_embeddings(EMBEDDING_FILE, tok)\n",
    "print(embedding_matrix.shape)\n",
    "print(np.mean(embedding_matrix), np.std(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        # self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))),\n",
    "                        (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        # print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0], self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroMaskedEntries(Layer):\n",
    "    \"\"\"\n",
    "    This layer is called after an Embedding layer.\n",
    "    It zeros out all of the masked-out embeddings.\n",
    "    It also swallows the mask without passing it on.\n",
    "    You can change this to default pass-on behavior as follows:\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        if not self.mask_zero:\n",
    "            return None\n",
    "        else:\n",
    "            return K.not_equal(x, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.support_mask = True\n",
    "        super(ZeroMaskedEntries, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.output_dim = input_shape[1]\n",
    "        self.repeat_dim = input_shape[2]\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        #print(mask.shape)\n",
    "        mask = K.cast(mask, 'float32')\n",
    "        mask = K.repeat(mask, self.repeat_dim)\n",
    "        #print(mask.shape)\n",
    "        mask = K.permute_dimensions(mask, (0, 2, 1))\n",
    "        return x * mask\n",
    "\n",
    "    def compute_mask(self, input_shape, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "def mask_aware_mean(x):\n",
    "    # recreate the masks - all zero rows have been masked\n",
    "    #mask = K.not_equal(K.sum(K.abs(x), axis=2, keepdims=True), 0)\n",
    "\n",
    "    # number of that rows are not all zeros\n",
    "    #n = K.sum(K.cast(mask, 'float32'), axis=1, keepdims=False)\n",
    "    # compute mask-aware mean of x\n",
    "    x_mean = K.sum(x, axis=1, keepdims=False)\n",
    "    #print(x_mean.shape)\n",
    "    return x_mean\n",
    "\n",
    "def mask_aware_mean_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3 \n",
    "    return (shape[0], shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class GRUClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, gru_dim=150, dense_dim=256, batch_size=128, epochs=2, bidirectional=False, \n",
    "                 pool_type='all', initial_weights=None, optimizer='adam' ,verbose=1, out_dim=6, callbacks=None):\n",
    "        \n",
    "        self.gru_dim = gru_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs= epochs\n",
    "        self.bidirectional = bidirectional\n",
    "        self.pool_type = pool_type\n",
    "        self.initial_weights = initial_weights\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.optimizer = optimizer\n",
    "        self.out_dim = out_dim\n",
    "    def _build_model(self):\n",
    "        inp = Input(shape=(MAX_LEN,))\n",
    "        emb = Embedding(MAX_FEATURES, \n",
    "                        EMBED_SIZE,\n",
    "                        weights=[self.initial_weights],\n",
    "                        mask_zero=True,\n",
    "                        #embeddings_regularizer=regularizers.l2(0.0001),\n",
    "                        trainable=True)(inp)\n",
    "\n",
    "        emb = ZeroMaskedEntries()(emb)\n",
    "        if self.bidirectional:\n",
    "            enc = Bidirectional(CuDNNGRU(int(self.gru_dim), return_sequences=True, return_state=True, \n",
    "                                         ))(emb)\n",
    "            x = enc[0]\n",
    "            state = enc[1]\n",
    "        else:\n",
    "            x, state = CuDNNGRU(int(self.gru_dim), return_sequences=True, return_state=True,\n",
    "                            #kernel_regularizer=regularizers.l2(0.0001),\n",
    "                            # recurrent_regularizer=regularizers.l2(0.0001),\n",
    "                             #bias_regularizer=regularizers.l2(0.0001)\n",
    "                               )(emb)\n",
    "            #x = SpatialDropout1D(0.5)(x)\n",
    "        \n",
    "        if self.pool_type == 'avg':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'max':\n",
    "            x = GlobalMaxPool1D()(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'attn':\n",
    "            x = Attention(MAX_LEN)(x)\n",
    "            x = concatenate([x, state])\n",
    "            \n",
    "        elif self.pool_type == 'all':\n",
    "            #x1 = GlobalAveragePooling1D()(x)\n",
    "            x2 = GlobalMaxPool1D()(x)\n",
    "            x3 = Attention(MAX_LEN)(x)\n",
    "            x = concatenate([x2, x3, state])\n",
    "    \n",
    "        #x = Dropout(0.5)(x)\n",
    "        x = Dense(self.dense_dim)(x)\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        out = Dense(self.out_dim, activation=\"sigmoid\")(x)\n",
    "        \n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=self.optimizer, metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "        if self.callbacks:\n",
    "            self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                       verbose=self.verbose,\n",
    "                       callbacks=self.callbacks,\n",
    "                       shuffle=True)\n",
    "        else:\n",
    "            self.model.fit(X, y, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                       verbose=self.verbose,\n",
    "                       shuffle=True)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        if self.model:\n",
    "            y_hat = self.model.predict(X, batch_size=2048)\n",
    "        else:\n",
    "            raise ValueError(\"Model not fit yet\")\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(epoch):\n",
    "    if epoch == 0:\n",
    "        return 0.0015\n",
    "    if epoch == 1:\n",
    "        return 0.0007\n",
    "    if epoch == 2:\n",
    "        return 0.001\n",
    "    if epoch == 3:\n",
    "        return 0.00001\n",
    "\n",
    "\n",
    "def shuffle_crossvalidator(model, cvlist, X, y):\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist2:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        print(\"ROC AUC for this fold is \", roc_auc_score(y_val, y_pred))\n",
    "        y_trues.append(y_val)\n",
    "        y_preds.append(y_pred)\n",
    "        K.clear_session()\n",
    "        #break\n",
    "    score = roc_auc_score(np.concatenate(y_trues), np.concatenate(y_preds))\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, score\n",
    "\n",
    "def outoffold_crossvalidator(model_params, cvlist, X, y):\n",
    "    y_preds = np.zeros(y.shape)\n",
    "    LRDecay = LearningRateScheduler(lr_decay)\n",
    "\n",
    "    for tr_index, val_index in cvlist2:\n",
    "        X_tr, y_tr = X[tr_index, :], y[tr_index, :]\n",
    "        X_val, y_val = X[val_index, :], y[val_index, :]\n",
    "        RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "        \n",
    "        model.set_params(**{'callbacks':[RocAuc, LRDecay]})\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        print(\"ROC AUC for this fold is \", roc_auc_score(y_val, y_pred))\n",
    "        y_preds[val_idx] = y_pred\n",
    "        K.clear_session()\n",
    "        #break\n",
    "    score = roc_auc_score(y, y_preds)\n",
    "    print(\"Overall score on 10 fold CV is {}\".format(score))\n",
    "    \n",
    "    return y_preds, y_trues, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "151552/151592 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9812\n",
      " ROC-AUC - epoch: 1 - score: 0.988671 \n",
      "\n",
      "151592/151592 [==============================] - 100s 660us/step - loss: 0.0500 - acc: 0.9812\n",
      "Epoch 2/2\n",
      "142720/151592 [===========================>..] - ETA: 5s - loss: 0.0324 - acc: 0.9867"
     ]
    }
   ],
   "source": [
    "model = GRUClassifier(gru_dim=500, dense_dim=600, initial_weights=embedding_matrix, bidirectional=False,\n",
    "                    batch_size=128, epochs=2, optimizer='adam')\n",
    "\n",
    "y_preds, y_trues, _ = shuffle_crossvalidator(model, cvlist2, X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_gru()\n",
    "model = GRUClassifier(initial_weights=embedding_matrix, bidirectonal=True,\n",
    "                    batch_size=128, epochs=2, optimizer='adam')\n",
    "\n",
    "y_preds, y_trues, _ = shuffle_crossvalidator(model, cvlist2, X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_trues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b5ca0b11927a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_trues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_trues' is not defined"
     ]
    }
   ],
   "source": [
    "np.concatenate(y_preds).shape\n",
    "y_trues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize, gbrt_minimize\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9795\n",
      " ROC-AUC - epoch: 1 - score: 0.982213 \n",
      "\n",
      "151592/151592 [==============================] - 36s 237us/step - loss: 0.0621 - acc: 0.9795\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9857\n",
      " ROC-AUC - epoch: 2 - score: 0.983151 \n",
      "\n",
      "151592/151592 [==============================] - 36s 238us/step - loss: 0.0364 - acc: 0.9857\n",
      "ROC AUC for this fold is  0.9831507887571517\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9793\n",
      " ROC-AUC - epoch: 1 - score: 0.982551 \n",
      "\n",
      "151592/151592 [==============================] - 36s 234us/step - loss: 0.0624 - acc: 0.9793\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9855\n",
      " ROC-AUC - epoch: 2 - score: 0.984904 \n",
      "\n",
      "151592/151592 [==============================] - 36s 234us/step - loss: 0.0368 - acc: 0.9855\n",
      "ROC AUC for this fold is  0.9849042706445514\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9789\n",
      " ROC-AUC - epoch: 1 - score: 0.978703 \n",
      "\n",
      "151592/151592 [==============================] - 36s 236us/step - loss: 0.0632 - acc: 0.9789\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9854\n",
      " ROC-AUC - epoch: 2 - score: 0.981460 \n",
      "\n",
      "151592/151592 [==============================] - 36s 235us/step - loss: 0.0367 - acc: 0.9854\n",
      "ROC AUC for this fold is  0.981459628816375\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9790\n",
      " ROC-AUC - epoch: 1 - score: 0.983140 \n",
      "\n",
      "151592/151592 [==============================] - 36s 239us/step - loss: 0.0627 - acc: 0.9790\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9854\n",
      " ROC-AUC - epoch: 2 - score: 0.985088 \n",
      "\n",
      "151592/151592 [==============================] - 36s 239us/step - loss: 0.0367 - acc: 0.9854\n",
      "ROC AUC for this fold is  0.985088204547639\n",
      "(?, 200, 188)\n",
      "Epoch 1/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9792\n",
      " ROC-AUC - epoch: 1 - score: 0.972825 \n",
      "\n",
      "151592/151592 [==============================] - 36s 240us/step - loss: 0.0623 - acc: 0.9792\n",
      "Epoch 2/2\n",
      "151389/151592 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9855\n",
      " ROC-AUC - epoch: 2 - score: 0.978548 \n",
      "\n",
      "151592/151592 [==============================] - 36s 239us/step - loss: 0.0367 - acc: 0.9855\n",
      "ROC AUC for this fold is  0.9785480076398568\n",
      "Overall score with params [188, 63, 693, 0.002718830808690577, 0.0009422336297274342, 0.00017228945369609434, 243] is -0.981908510143595\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9801\n",
      " ROC-AUC - epoch: 1 - score: 0.979619 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0590 - acc: 0.9801\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.981688 \n",
      "\n",
      "151592/151592 [==============================] - 51s 336us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.9816875864328961\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151443/151592 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9799\n",
      " ROC-AUC - epoch: 1 - score: 0.982151 \n",
      "\n",
      "151592/151592 [==============================] - 51s 336us/step - loss: 0.0587 - acc: 0.9799\n",
      "Epoch 2/2\n",
      "151443/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.983661 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.983660603408001\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.977208 \n",
      "\n",
      "151592/151592 [==============================] - 51s 338us/step - loss: 0.0593 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9843\n",
      " ROC-AUC - epoch: 2 - score: 0.980129 \n",
      "\n",
      "151592/151592 [==============================] - 51s 336us/step - loss: 0.0410 - acc: 0.9843\n",
      "ROC AUC for this fold is  0.9801287959042814\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.979554 \n",
      "\n",
      "151592/151592 [==============================] - 51s 337us/step - loss: 0.0593 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.983189 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0406 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.9831890064421351\n",
      "(?, 200, 37)\n",
      "Epoch 1/2\n",
      "151443/151592 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9800\n",
      " ROC-AUC - epoch: 1 - score: 0.970716 \n",
      "\n",
      "151592/151592 [==============================] - 51s 337us/step - loss: 0.0585 - acc: 0.9800\n",
      "Epoch 2/2\n",
      "151585/151592 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.975606 \n",
      "\n",
      "151592/151592 [==============================] - 51s 335us/step - loss: 0.0407 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.975606190503571\n",
      "Overall score with params [37, 52, 663, 0.0032741274355183713, 0.001649745367819878, 8.264328927007725e-07, 71] is -0.9797327192914483\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9756\n",
      " ROC-AUC - epoch: 1 - score: 0.976287 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0825 - acc: 0.9756\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9827\n",
      " ROC-AUC - epoch: 2 - score: 0.978553 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0461 - acc: 0.9827\n",
      "ROC AUC for this fold is  0.9785534459059586\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9755\n",
      " ROC-AUC - epoch: 1 - score: 0.975004 \n",
      "\n",
      "151592/151592 [==============================] - 58s 380us/step - loss: 0.0827 - acc: 0.9755\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9826\n",
      " ROC-AUC - epoch: 2 - score: 0.981197 \n",
      "\n",
      "151592/151592 [==============================] - 57s 379us/step - loss: 0.0466 - acc: 0.9826\n",
      "ROC AUC for this fold is  0.981196558500094\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9758\n",
      " ROC-AUC - epoch: 1 - score: 0.971721 \n",
      "\n",
      "151592/151592 [==============================] - 57s 379us/step - loss: 0.0817 - acc: 0.9758\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9824\n",
      " ROC-AUC - epoch: 2 - score: 0.976544 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0467 - acc: 0.9824\n",
      "ROC AUC for this fold is  0.9765437382948529\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9752\n",
      " ROC-AUC - epoch: 1 - score: 0.967915 \n",
      "\n",
      "151592/151592 [==============================] - 58s 380us/step - loss: 0.0840 - acc: 0.9752\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9821\n",
      " ROC-AUC - epoch: 2 - score: 0.980064 \n",
      "\n",
      "151592/151592 [==============================] - 57s 378us/step - loss: 0.0488 - acc: 0.9821\n",
      "ROC AUC for this fold is  0.9800638633500763\n",
      "(?, 200, 103)\n",
      "Epoch 1/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9756\n",
      " ROC-AUC - epoch: 1 - score: 0.962656 \n",
      "\n",
      "151592/151592 [==============================] - 58s 380us/step - loss: 0.0822 - acc: 0.9756\n",
      "Epoch 2/2\n",
      "151560/151592 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9825\n",
      " ROC-AUC - epoch: 2 - score: 0.974217 \n",
      "\n",
      "151592/151592 [==============================] - 57s 379us/step - loss: 0.0464 - acc: 0.9825\n",
      "ROC AUC for this fold is  0.9742171289594977\n",
      "Overall score with params [103, 190, 664, 0.00046486793036106645, 0.0008391552454523785, 4.863857046189473e-07, 180] is -0.9763636697443007\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9800\n",
      " ROC-AUC - epoch: 1 - score: 0.982381 \n",
      "\n",
      "151592/151592 [==============================] - 60s 399us/step - loss: 0.0577 - acc: 0.9800\n",
      "Epoch 2/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9850\n",
      " ROC-AUC - epoch: 2 - score: 0.983000 \n",
      "\n",
      "151592/151592 [==============================] - 61s 400us/step - loss: 0.0378 - acc: 0.9850\n",
      "ROC AUC for this fold is  0.9830000592787996\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9757\n",
      " ROC-AUC - epoch: 1 - score: 0.479192 \n",
      "\n",
      "151592/151592 [==============================] - 61s 399us/step - loss: 0.1725 - acc: 0.9757\n",
      "Epoch 2/2\n",
      "151436/151592 [============================>.] - ETA: 0s - loss: 0.5797 - acc: 0.9636\n",
      " ROC-AUC - epoch: 2 - score: 0.478979 \n",
      "\n",
      "151592/151592 [==============================] - 60s 398us/step - loss: 0.5796 - acc: 0.9636\n",
      "ROC AUC for this fold is  0.47897871742656667\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9800\n",
      " ROC-AUC - epoch: 1 - score: 0.980220 \n",
      "\n",
      "151592/151592 [==============================] - 61s 400us/step - loss: 0.0579 - acc: 0.9800\n",
      "Epoch 2/2\n",
      "151436/151592 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9854\n",
      " ROC-AUC - epoch: 2 - score: 0.981055 \n",
      "\n",
      "151592/151592 [==============================] - 61s 401us/step - loss: 0.0371 - acc: 0.9854\n",
      "ROC AUC for this fold is  0.981055035868211\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9801\n",
      " ROC-AUC - epoch: 1 - score: 0.983936 \n",
      "\n",
      "151592/151592 [==============================] - 61s 404us/step - loss: 0.0575 - acc: 0.9802\n",
      "Epoch 2/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9853\n",
      " ROC-AUC - epoch: 2 - score: 0.984244 \n",
      "\n",
      "151592/151592 [==============================] - 61s 403us/step - loss: 0.0370 - acc: 0.9853\n",
      "ROC AUC for this fold is  0.9842439726685116\n",
      "(?, 200, 131)\n",
      "Epoch 1/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9795\n",
      " ROC-AUC - epoch: 1 - score: 0.972591 \n",
      "\n",
      "151592/151592 [==============================] - 61s 400us/step - loss: 0.0584 - acc: 0.9795\n",
      "Epoch 2/2\n",
      "151567/151592 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9851\n",
      " ROC-AUC - epoch: 2 - score: 0.973719 \n",
      "\n",
      "151592/151592 [==============================] - 61s 399us/step - loss: 0.0381 - acc: 0.9851\n",
      "ROC AUC for this fold is  0.9737194283554632\n",
      "Overall score with params [131, 224, 819, 0.004228417918653105, 2.1035428134349117e-05, 0.00022409712855921124, 131] is -0.8089338526899862\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9770\n",
      " ROC-AUC - epoch: 1 - score: 0.977211 \n",
      "\n",
      "151592/151592 [==============================] - 69s 457us/step - loss: 0.0725 - acc: 0.9770\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9841\n",
      " ROC-AUC - epoch: 2 - score: 0.978639 \n",
      "\n",
      "151592/151592 [==============================] - 70s 459us/step - loss: 0.0417 - acc: 0.9841\n",
      "ROC AUC for this fold is  0.9786387471844195\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9769\n",
      " ROC-AUC - epoch: 1 - score: 0.978410 \n",
      "\n",
      "151592/151592 [==============================] - 70s 460us/step - loss: 0.0737 - acc: 0.9770\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9839\n",
      " ROC-AUC - epoch: 2 - score: 0.980503 \n",
      "\n",
      "151592/151592 [==============================] - 69s 458us/step - loss: 0.0422 - acc: 0.9839\n",
      "ROC AUC for this fold is  0.9805028987671683\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9771\n",
      " ROC-AUC - epoch: 1 - score: 0.978405 \n",
      "\n",
      "151592/151592 [==============================] - 70s 460us/step - loss: 0.0719 - acc: 0.9771\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9841\n",
      " ROC-AUC - epoch: 2 - score: 0.978896 \n",
      "\n",
      "151592/151592 [==============================] - 69s 458us/step - loss: 0.0412 - acc: 0.9841\n",
      "ROC AUC for this fold is  0.9788959372266136\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9774\n",
      " ROC-AUC - epoch: 1 - score: 0.979097 \n",
      "\n",
      "151592/151592 [==============================] - 69s 453us/step - loss: 0.0730 - acc: 0.9774\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9838\n",
      " ROC-AUC - epoch: 2 - score: 0.981427 \n",
      "\n",
      "151592/151592 [==============================] - 69s 454us/step - loss: 0.0424 - acc: 0.9838\n",
      "ROC AUC for this fold is  0.9814265132458532\n",
      "(?, 200, 232)\n",
      "Epoch 1/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9776\n",
      " ROC-AUC - epoch: 1 - score: 0.966967 \n",
      "\n",
      "151592/151592 [==============================] - 70s 459us/step - loss: 0.0711 - acc: 0.9776\n",
      "Epoch 2/2\n",
      "151425/151592 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.973075 \n",
      "\n",
      "151592/151592 [==============================] - 70s 460us/step - loss: 0.0411 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.973075106237849\n",
      "Overall score with params [232, 193, 819, 0.0007660826482436302, 0.00036485656261804145, 4.010174523739503e-05, 225] is -0.9779524572618891\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9772\n",
      " ROC-AUC - epoch: 1 - score: 0.975908 \n",
      "\n",
      "151592/151592 [==============================] - 45s 294us/step - loss: 0.0714 - acc: 0.9772\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.976649 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0438 - acc: 0.9836\n",
      "ROC AUC for this fold is  0.9766493775364063\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9776\n",
      " ROC-AUC - epoch: 1 - score: 0.979397 \n",
      "\n",
      "151592/151592 [==============================] - 45s 295us/step - loss: 0.0708 - acc: 0.9776\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9836\n",
      " ROC-AUC - epoch: 2 - score: 0.979504 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0436 - acc: 0.9836\n",
      "ROC AUC for this fold is  0.979503631593044\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9768\n",
      " ROC-AUC - epoch: 1 - score: 0.976003 \n",
      "\n",
      "151592/151592 [==============================] - 45s 294us/step - loss: 0.0720 - acc: 0.9768\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9835\n",
      " ROC-AUC - epoch: 2 - score: 0.976447 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0436 - acc: 0.9835\n",
      "ROC AUC for this fold is  0.9764472327389656\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9777\n",
      " ROC-AUC - epoch: 1 - score: 0.979131 \n",
      "\n",
      "151592/151592 [==============================] - 45s 294us/step - loss: 0.0698 - acc: 0.9777\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9835\n",
      " ROC-AUC - epoch: 2 - score: 0.980186 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0432 - acc: 0.9835\n",
      "ROC AUC for this fold is  0.9801854316928432\n",
      "(?, 200, 25)\n",
      "Epoch 1/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9749\n",
      " ROC-AUC - epoch: 1 - score: 0.969714 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0787 - acc: 0.9749\n",
      "Epoch 2/2\n",
      "151575/151592 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9831\n",
      " ROC-AUC - epoch: 2 - score: 0.971242 \n",
      "\n",
      "151592/151592 [==============================] - 44s 293us/step - loss: 0.0447 - acc: 0.9831\n",
      "ROC AUC for this fold is  0.9712422297781508\n",
      "Overall score with params [25, 201, 703, 0.001944756315639371, 1.7526555841926e-05, 2.333469328026268e-06, 235] is -0.9767305384316131\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9795\n",
      " ROC-AUC - epoch: 1 - score: 0.977509 \n",
      "\n",
      "151592/151592 [==============================] - 127s 841us/step - loss: 0.0613 - acc: 0.9795\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.978575 \n",
      "\n",
      "151592/151592 [==============================] - 127s 838us/step - loss: 0.0406 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.9785749695939608\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9796\n",
      " ROC-AUC - epoch: 1 - score: 0.979589 \n",
      "\n",
      "151592/151592 [==============================] - 127s 840us/step - loss: 0.0607 - acc: 0.9796\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.980123 \n",
      "\n",
      "151592/151592 [==============================] - 127s 836us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.9801229709965509\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.977616 \n",
      "\n",
      "151592/151592 [==============================] - 127s 838us/step - loss: 0.0608 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9842\n",
      " ROC-AUC - epoch: 2 - score: 0.978647 \n",
      "\n",
      "151592/151592 [==============================] - 127s 837us/step - loss: 0.0408 - acc: 0.9842\n",
      "ROC AUC for this fold is  0.9786470731369955\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9799\n",
      " ROC-AUC - epoch: 1 - score: 0.979844 \n",
      "\n",
      "151592/151592 [==============================] - 127s 838us/step - loss: 0.0605 - acc: 0.9799\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9844\n",
      " ROC-AUC - epoch: 2 - score: 0.980418 \n",
      "\n",
      "151592/151592 [==============================] - 127s 837us/step - loss: 0.0402 - acc: 0.9844\n",
      "ROC AUC for this fold is  0.9804184726612338\n",
      "(?, 200, 130)\n",
      "Epoch 1/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9797\n",
      " ROC-AUC - epoch: 1 - score: 0.971314 \n",
      "\n",
      "151592/151592 [==============================] - 127s 837us/step - loss: 0.0607 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "151550/151592 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9845\n",
      " ROC-AUC - epoch: 2 - score: 0.971221 \n",
      "\n",
      "151592/151592 [==============================] - 127s 836us/step - loss: 0.0403 - acc: 0.9845\n",
      "ROC AUC for this fold is  0.971220699938803\n",
      "Overall score with params [130, 199, 92, 0.0009241707704121684, 1.1046784818354062e-05, 1.225116771800311e-05, 70] is -0.977704066116015\n",
      "(?, 200, 248)\n",
      "Epoch 1/2\n",
      "151569/151592 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9810\n",
      " ROC-AUC - epoch: 1 - score: 0.982994 \n",
      "\n",
      "151592/151592 [==============================] - 199s 1ms/step - loss: 0.0541 - acc: 0.9810\n",
      "Epoch 2/2\n",
      "120087/151592 [======================>.......] - ETA: 41s - loss: 0.0348 - acc: 0.9862"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7f5c9ce2e51f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         ]\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mres_gp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbrt_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skopt/optimizer/gbrt.py\u001b[0m in \u001b[0;36mgbrt_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    151\u001b[0m                          \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                          \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                          callback=callback, acq_optimizer=\"sampling\")\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-704d933bb7dd>\u001b[0m in \u001b[0;36mtrain_gru\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         model.fit(X_train, y_train, batch_size=batch_size, epochs=2, validation_split=0.0, verbose=1, \n\u001b[0;32m---> 56\u001b[0;31m                   callbacks=[RocAuc, LRDecay])\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC AUC for this fold is \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space = [Integer(16, 256), #name='embed_size'),\n",
    "         Integer(16, 256),# name='gru_dim'),\n",
    "         Integer(64, 1024),# name='dense_dim'),\n",
    "         Real(0.0001, 0.005, \"log-uniform\"), #name='lr1'),\n",
    "         Real(1e-5, 0.002, \"log-uniform\"), #name='lr2'),\n",
    "         Real(1e-8, 0.001, \"log-uniform\"), #name='decay'),\n",
    "         Integer(32, 256),# name=batch'),\n",
    "        ]\n",
    "\n",
    "res_gp = gbrt_minimize(train_gru, space, n_calls=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_trues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-3f5efbe5120f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_trues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_trues' is not defined"
     ]
    }
   ],
   "source": [
    "y_trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861737784746518"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "159456/159571 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9818\n",
      " ROC-AUC - epoch: 1 - score: 0.992135 \n",
      "\n",
      "159571/159571 [==============================] - 84s 528us/step - loss: 0.0498 - acc: 0.9818\n",
      "Epoch 2/3\n",
      "159488/159571 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9850\n",
      " ROC-AUC - epoch: 2 - score: 0.995249 \n",
      "\n",
      "159571/159571 [==============================] - 83s 523us/step - loss: 0.0384 - acc: 0.9850\n",
      "Epoch 3/3\n",
      "159488/159571 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9880\n",
      " ROC-AUC - epoch: 3 - score: 0.995429 \n",
      "\n",
      "159571/159571 [==============================] - 84s 525us/step - loss: 0.0307 - acc: 0.9880\n",
      "153164/153164 [==============================] - 2s 15us/step\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_t, y, batch_size=32, epochs=3, validation_split=0.0, verbose=1, \n",
    "              callbacks=[RocAuc, LRDecay])\n",
    "y_test_preds = model.predict([X_te], batch_size=1024, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for class toxic is 0.9791088111561013\n",
      "Score for class severe_toxic is 0.9896361881404786\n",
      "Score for class obscene is 0.989792727484462\n",
      "Score for class threat is 0.9834375512104746\n",
      "Score for class insult is 0.9851961777705942\n",
      "Score for class identity_hate is 0.9837426177272286\n",
      "Over auc score 0.9851523455815565\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_trues = train[label_cols].values\n",
    "y_preds2 = np.zeros((X_t.shape[0], len(label_cols)))\n",
    "y_test_preds2 = np.zeros((X_te.shape[0], len(label_cols)))\n",
    "for i, col in enumerate(label_cols):\n",
    "    y = y_trues[:, i]\n",
    "    #model = RandomForestClassifier(n_estimators=100, max_depth=6, min_samples_leaf=50, class_weight='balanced', n_jobs=-1)\n",
    "    model = lgb.LGBMClassifier(n_estimators=100, num_leaves=5, learning_rate=0.03, \n",
    "                               subsample=0.9, colsample_bytree=0.9)\n",
    "    y_preds2[:, i] = cross_val_predict(model, y_preds, y, cv=cvlist, n_jobs=1, method='predict_proba')[:,1]\n",
    "    y_test_preds2[:, i] = model.fit(y_preds, y).predict_proba(y_test_preds)[:,1]\n",
    "    print(\"Score for class {} is {}\".format(col, roc_auc_score(y, y_preds2[:, i])))\n",
    "print(\"Over auc score\", roc_auc_score(y_trues, y_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[label_cols] = y_test_preds\n",
    "sample_submission.to_csv('nn_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[label_cols] = y_test_preds2\n",
    "sample_submission.to_csv('nn_lgbmeta_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
